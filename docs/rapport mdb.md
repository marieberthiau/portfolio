---
title: "Trafic cycliste √† Paris de septembre 2024 √† octobre 2025"
author: "Marie Berthiau"
date: "Novembre 2024"
description: "Rapport final individuel de projet dans le cadre de la formation Data Analyst de DataScientest"
subject: "Analyse de donn√©es"
keywords: ["data analysis", "cyclisme", "Paris", "trafic"]
lang: "fr"
toc: true
toc-title: "Sommaire"
toc-depth: 4
markdown.styles: ["style.css"]
markdown-pdf.styles: ["style.css"]
pdf_options:
  format: A4
  margin: 20mm
  printBackground: true
---

<center><img src=".\images\pont_concorde.jpg" style="height:200px"></center>

# Trafic cycliste √† Paris de septembre 2024 √† octobre 2025

- [I. D√©couverte des donn√©es et du projet ](#i-d√©couverte-des-donn√©es-et-du-projet-)
  - [I.A. Objectifs du projet et enjeux ](#ia-objectifs-du-projet-et-enjeux-)
  - [I.B. Structure du projet et organisation du groupe ](#ib-structure-du-projet-et-organisation-du-groupe-)
  - [I.C. Mise en contexte ](#ic-mise-en-contexte-)
    - [I.C.1. Contexte politique ](#ic1-contexte-politique-)
    - [I.C.2. Contexte technique ](#ic2-contexte-technique-)
    - [I.C.3. Int√©r√™t personnel au projet ](#ic3-int√©r√™t-personnel-au-projet-)
  - [I.D. D√©couverte du jeu de donn√©es ](#id-d√©couverte-du-jeu-de-donn√©es-)
    - [I.D.1 Biais et difficult√©s potentielles *a priori* ](#id1-biais-et-difficult√©s-potentielles-a-priori-)
    - [I.D.2 Exploration du jeu sur l'OpenData de la ville de Paris. ](#id2-exploration-du-jeu-sur-lopendata-de-la-ville-de-paris-)
  - [I.E. Bilan de l'√©tape de d√©couverte des donn√©es](#ie-bilan-de-l√©tape-de-d√©couverte-des-donn√©es)
- [II. Pr√©-processing](#ii-pr√©-processing)
  - [II.A. Pr√©processing du jeu principal avec Python ](#iia-pr√©processing-du-jeu-principal-avec-python-)
    - [II.A.1. Exploration d√©taill√©e des jeux de donn√©es 'comptage \& compteurs' ](#iia1-exploration-d√©taill√©e-des-jeux-de-donn√©es-comptage--compteurs-)
    - [II.A.2. Pr√©paration du jeu principal ](#iia2-pr√©paration-du-jeu-principal-)
      - [II.A.2.a. Pr√©paration du jeu principal](#iia2a-pr√©paration-du-jeu-principal)
      - [II.A.2.c. Extraction du jeu de comptage](#iia2c-extraction-du-jeu-de-comptage)
      - [II.A.2.b. Extraction du jeu de compteur](#iia2b-extraction-du-jeu-de-compteur)
    - [II.A.3. G√©olocalisation des compteurs  ](#iia3-g√©olocalisation-des-compteurs--)
    - [II.B. Exploration et Pr√©processing des jeux d'enrichissement avec Python  ](#iib-exploration-et-pr√©processing-des-jeux-denrichissement-avec-python--)
      - [II.B.1 Jeu de donn√©es m√©t√©orologique ](#iib1-jeu-de-donn√©es-m√©t√©orologique-)
      - [II.B.2. Jeu de donn√©es de l'enqu√™te de la FUB ](#iib2-jeu-de-donn√©es-de-lenqu√™te-de-la-fub-)
        - [II.B.2.a. Exploration des clusters du barom√®tre FUB ](#iib2a-exploration-des-clusters-du-barom√®tre-fub-)
        - [II.B.2.b. 2√®me phase de l'exploration g√©ographique du barom√®tre FUB ](#iib2b-2√®me-phase-de-lexploration-g√©ographique-du-barom√®tre-fub-)
      - [II.B.3. Pr√©paration des avis pour l'analyse textuelle ](#iib3-pr√©paration-des-avis-pour-lanalyse-textuelle-)
        - [II.B.3.a. Normalisation et lemmatisation du texte en fran√ßais ](#iib3a-normalisation-et-lemmatisation-du-texte-en-fran√ßais-)
        - [II.B.3.b. Cr√©ation d'un nuage de mot suivant 2 algorithmes diff√©rents ](#iib3b-cr√©ation-dun-nuage-de-mot-suivant-2-algorithmes-diff√©rents-)
        - [II.B.3.c. Choix de l'algorithme le plus pertinent ](#iib3c-choix-de-lalgorithme-le-plus-pertinent-)
      - [II.B.4. Jointure g√©ospatiale des avis ](#iib4-jointure-g√©ospatiale-des-avis-)
      - [II.B.5. Fichiers obtenus √† l'issu de cette √©tape ](#iib5-fichiers-obtenus-√†-lissu-de-cette-√©tape-)
    - [II.C. Pr√©processing dans Power Query ](#iic-pr√©processing-dans-power-query-)
      - [II.C.1. Collecte des donn√©es ](#iic1-collecte-des-donn√©es-)
      - [II.C.2. Transformations sur la table des compteurs ](#iic2-transformations-sur-la-table-des-compteurs-)
      - [II.C.3. Cr√©ation d'un score m√©t√©o ](#iic3-cr√©ation-dun-score-m√©t√©o-)
    - [II.D. Pr√©processing dans Power BI ](#iid-pr√©processing-dans-power-bi-)
      - [II.D.1. Cr√©ation des tables de date ](#iid1-cr√©ation-des-tables-de-date-)
      - [II.D.2. Mod√©lisation en √©toile ](#iid2-mod√©lisation-en-√©toile-)
      - [II.D.3. Cr√©ation des hi√©rarchies ](#iid3-cr√©ation-des-hi√©rarchies-)
      - [II.D.4. Cr√©ation des mesures de sensibilit√© √† la m√©t√©o ](#iid4-cr√©ation-des-mesures-de-sensibilit√©-√†-la-m√©t√©o-)
      - [II.D.5. Cr√©ation des mesures de saturation des am√©nagements ](#iid5-cr√©ation-des-mesures-de-saturation-des-am√©nagements-)
- [III. Visualisations dans Power BI ](#iii-visualisations-dans-power-bi-)
  - [III.A. Th√®me et organisations visuelles des pages](#iiia-th√®me-et-organisations-visuelles-des-pages)
  - [III.B. La page d'accueil du rapport](#iiib-la-page-daccueil-du-rapport)
  - [III.C. La page de Focus Site](#iiic-la-page-de-focus-site)
- [IV. Analyse des donn√©es ](#iv-analyse-des-donn√©es-)
- [Conclusion](#conclusion)
  - [Bilan](#bilan)
  - [Perspectives :](#perspectives-)
  - [Les difficult√©s qu'il a fallu relever](#les-difficult√©s-quil-a-fallu-relever)
- [Bibliographie](#bibliographie)
  - [1. Plans v√©lo et qualit√© de l'air](#1-plans-v√©lo-et-qualit√©-de-lair)
  - [2. D√©placements √† Paris](#2-d√©placements-√†-paris)
  - [3. Qualit√© des am√©nagements cyclables (Guides officiels )](#3-qualit√©-des-am√©nagements-cyclables-guides-officiels-)
  - [4. Paris en Selle ](#4-paris-en-selle-)
  - [5. Compr√©hension des fonctionnement des capteurs et des m√©thodes de suivi du trafic](#5-compr√©hension-des-fonctionnement-des-capteurs-et-des-m√©thodes-de-suivi-du-trafic)
  - [6. Documentation technique compl√©mentaire](#6-documentation-technique-compl√©mentaire)
- [Annexes et extrait de code](#annexes-et-extrait-de-code)
  - [Annexe 1 : üóÇÔ∏è Structure du projet et du fichier zip](#annexe-1--Ô∏è-structure-du-projet-et-du-fichier-zip)
  - [Annexes 2 : Struture des jeux de donn√©ees initiaux](#annexes-2--struture-des-jeux-de-donn√©ees-initiaux)
    - [Annexe 2a : Structure du jeu de donn√©es initial brut](#annexe-2a--structure-du-jeu-de-donn√©es-initial-brut)
    - [Annexe 2b : Structure du jeu de donn√©es m√©t√©o](#annexe-2b--structure-du-jeu-de-donn√©es-m√©t√©o)
    - [Annexe 2c : Notice du jeu de donn√©es du barom√®tre FUB](#annexe-2c--notice-du-jeu-de-donn√©es-du-barom√®tre-fub)
  - [Annexe 3 : Script : superposition des compteurs et clusters du barom√®tre FUB"](#annexe-3--script--superposition-des-compteurs-et-clusters-du-barom√®tre-fub)
  - [Annexes 4 : Analyses textuelles](#annexes-4--analyses-textuelles)
    - [Annexe 4a : Normalisation et lemmatisation des avis](#annexe-4a--normalisation-et-lemmatisation-des-avis)
    - [Annexe 4b : Comparaison de 2 algorithmes de cr√©ation de nuage de mot](#annexe-4b--comparaison-de-2-algorithmes-de-cr√©ation-de-nuage-de-mot)
  - [Annexes 5 : Jointure g√©ospatiale des commentaires et compteurs](#annexes-5--jointure-g√©ospatiale-des-commentaires-et-compteurs)
    - [Annexe 5b : Script de d√©termination du rayon seuil de proximit√©](#annexe-5b--script-de-d√©termination-du-rayon-seuil-de-proximit√©)
    - [Annexe 5b : Script de Jointure g√©ospatiale](#annexe-5b--script-de-jointure-g√©ospatiale)
  - [Annexe 6 : Transformation des adresses et gestion de l'encodage](#annexe-6--transformation-des-adresses-et-gestion-de-lencodage)
  - [Annexe 7 : Colonnes calcul√©es de score m√©t√©o](#annexe-7--colonnes-calcul√©es-de-score-m√©t√©o)
  - [Annexe 8 : Exemple de mesure DAX de calcul des sensibilit√©s m√©t√©o](#annexe-8--exemple-de-mesure-dax-de-calcul-des-sensibilit√©s-m√©t√©o)
    - [Mesures interm√©diaires pour le calcul de la sensibilit√© √† la pluie](#mesures-interm√©diaires-pour-le-calcul-de-la-sensibilit√©-√†-la-pluie)
    - [Mesure de la sensibilit√© √† la pluie](#mesure-de-la-sensibilit√©-√†-la-pluie)
    - [Mesures pour le choix dynamique de l'effet](#mesures-pour-le-choix-dynamique-de-leffet)
  - [Annexe 9 : Mesure DAX de calcul des jours d√©passant un seuil journalier](#annexe-9--mesure-dax-de-calcul-des-jours-d√©passant-un-seuil-journalier)
  - [Annexe 10 : Script "nuage de mot" dans Power BI](#annexe-10--script-nuage-de-mot-dans-power-bi)

<hr class="page-break">

## I. D√©couverte des donn√©es et du projet <a id="I"></a>

### I.A. Objectifs du projet et enjeux <a id="IA"></a>

Le jeu de donn√©e sur lequel nous avons travaill√© est celui des [comptages V√©lo de la Ville de Paris](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/information/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name).
C'est un jeu relativement lourd de 1,44Go, mis √† jour quotidiennement sur une p√©riode de 13 mois glissants.<br><br>

La fiche projet mentionne explicitement les attendus suivants :

* **livrable :** doit permettre de visualiser les *horaires* et les *zones d'affluences*;
* **public concern√© :** Mairie de Paris (public de d√©cideur jugeant des d√©cisions d'am√©liorations √† apporter sur les am√©nagements).

Notre objectif √©tait donc de pr√©aprer un rapport destin√© aider ces d√©cideurs √† programmer les futurs am√©nagements cyclables.<br>
S'agissant d'un public de d√©cideur, nous aurons pour objectif de limiter le nombre d'√©cran sur notre rapport et de donn√©es des clefs de priorisation des actions.

Le pr√©sent rapport √† quant √† lui pour objectif de vous pr√©senter notre d√©marche et comment nous avons mis en place cette exploitation de donn√©es.<br>

### I.B. Structure du projet et organisation du groupe <a id="IB"></a>

Le projet est stock√© sur un [d√©p√¥t GitHub priv√© de Marie](https://github.com/marieberthiau/trafic_cycliste_a_Paris), les autres membres de l'√©quipe y √©tant collaborateurs.
Chaque membre du projet travaille localement avec VS Code, sur une branche <u>distincte</u> et des fusions sont faites ponctuellement apr√®s demande de tirage.
L'architecture g√©n√©rale du projet est d√©taill√©e en <a href="#ann1">Annexe 1</a>.
Je reviendrai dans le bilan sur la d√©couverte de Git qui a √©t√© en soi un <a href="#defi1">d√©fi √† relever</a>.

### I.C. Mise en contexte <a id="IC"></a>

#### I.C.1. Contexte politique <a id="IC1"></a>

Le [Plan National V√©lo et Marche 2023-2027](https://www.ecologie.gouv.fr/politiques-publiques/velo-marche-modes-deplacement-vertueux-avantageux) pr√©voit le financement d‚Äôinfrastructures cyclables.

La Ville de Paris, comme de nombreuses autre ville, d√©ploie depuis plusieurs ann√©es des compteurs √† v√©lo permanents pour √©valuer le d√©veloppement de la pratique cycliste.
En particulier, l'√©quipe municipale actuelle √† d√©ploy√© un [Plan v√©lo 2021-2026](https://www.paris.fr/pages/un-nouveau-plan-velo-pour-une-ville-100-cyclable-19554) qui met en avant :
* le recensement des ‚Äúpoints noirs‚Äù;
* la s√©curisation des carrefours, le jalonnement et le nettoiement des am√©nagements cyclables.

Ceci correspond √† un objectif de favoriser la transition vers des mobilit√©s douces et/ou actives.<br><br>

La mise en place de ces compteurs a donc g√©n√©ralement pour objectif :
* de promouvoir la mobilit√© durable en suivant la progression du v√©lo dans les trajets urbains;
* d'identifier les axes de transits principaux afin de hierarchiser un r√©seau cyclable en d√©veloppement en fonction des d√©bits <b>souhait√©s</b> (postulat de trafic induit : l'am√©nagement va √™tre le d√©clencheur de l'augmentation du trafic<a href="#bib101" class="ref">[1a]</a>. Ce n'est pas l'augmentation de trafic qui doit √™tre le d√©clencheur de l'am√©nagement d'une voirie.)
* de mesurer l'efficacit√© des am√©nagements mis en place (effet avant/apr√®s) ainsi que de faciliter l'estimation de la part modale du v√©lo √† Paris.<br>

Si cette part modale a en effet connu un doublement entre 2015 et entre 2020, elle tourne aujourd‚Äôhui autour de 10% <a href="#bib201" class="ref">[2a]</a>, ce qui reste relativement faible par rapport √† d'autres capitales europ√©enne. L'objectif est donc d'augmenter cette part et un flux faible dans une rue sur laquelle un compteur est install√© sera donc un flux sur lequel on recherche une tendance haussi√®re √† moyen-long terme.<br><br>

<div style="display: table; width: 100%;">
  <div style="display: table-cell; width: 65%; vertical-align: top; padding-right: 12px;">
      Il est int√©ressant de noter que la ville de Paris a mis en place un suivi d'indicateur sur la base de ces relev√©s de compteurs qui est publi√© annuellement <a href="#bib202" class="ref">[2b]</a>.
      Nous pouvons ainsi consulter le bilan 2024 des d√©placements √† v√©lo √† Paris et remarquer par exemple que le premier indicateur est bas√© sur l'identification des sites de comptage d√©passant les 3000 cyclistes / jour ouvr√©.<br>
      Nous reviendrons sur la prise en compte de ce seuil issu des recommandations du Cerema (Centre d'√©tudes et d'expertise sur les risques, l'environnement, la mobilit√© et l'am√©nagement, √©tablissement public relevant du minist√®re de la Transition √©cologique et de la Coh√©sion des territoires) lors de la <a id="#IIC4">pr√©paration de notre rapport Power Bi</a>.
  </div>
  <div style="display: table-cell; width: 30%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/debit_souhait√©_et_am√©nagements.png" alt="d√©bit cycliste souhait√© et type d'am√©nagement" style ="max-width: 200px; max-height: 200px;">
        <figcaption>
        Figure 1 ‚Äî Recommandations du Cerema
        </figcaption>
    </figure>
   </div>
</div>

#### I.C.2. Contexte technique <a id="IC2"></a>

[EcoCompteur](https://www.eco-compteur.com/expertise/?gclid=EAIaIQobChMI1e_cneec6QIV1PhRCh0XbQAyEAAYASAAEgL9gvD_BwE) qui g√®re les compteurs v√©lo met √† disposition les donn√©es √† la Ville de Paris via une API bas√©e sur REST et utilisant JSON.
EcoCompteur est √©galement partenaire d'autres agglom√©rations (Lyon, Toulouse, Rennes, Tours, Saint-Nazaire...), le type d'analyse que nous allons r√©aliser devrait th√©oriquement pouvoir √™tre transpos√©s √† ces localit√©s... sous r√©serve de prise en compte des retraitements.

Il faut noter que le jeu de donn√©es ne concerne que les compteurs de type "permanents", √† l'exclusion des compteurs de "cam√©ras thermique".<br>
La technologie <a href="#bib501" class="ref">[5a]</a> utilis√©e est majoritairement celle du magn√©tom√®tre noy√© dans le rev√™tement de la bande ou piste cyclable (d√©tection de la signature magn√©tique des roues de v√©lo). Les compteurs mis en place √† Paris sont en mesure de distinguer les v√©hicules motoris√©s et les trotinettes des v√©los <a href="#bib502" class="ref">[5b]</a>.
Cela signifie qu'un v√©lo est d√©compt√© lorsqu'il passe sur le compteur... mais pas √† c√¥t√© (en cas de circulation d√©vi√©e ou de v√©hicule stationn√© sur l'am√©nagement par exemple).

La Ville de Paris charge quotidiennement le jeu de donn√©e sur la base de cette API et effectue des retraitements pour au moins 2 raisons :

 - palier au fait que l'API Eco Compteur ne fournit pas nativement le comptage par sens de circulation,
 - effectuer une jointure avec un autre jeu de donn√©e, correspondant √† la description des compteurs, leurs localisations et dates d'installation.

Il faut noter que  ce jeu conserve uniquement les donn√©es sur 13 mois glissants √† J-1 mais qu'elle met √©galement √† jour des jeux de donn√©es sur d'autres plages temporelles (par exemple depuis 2019).

#### I.C.3. Int√©r√™t personnel au projet <a id="IC3"></a>

D'un point de vue individuel, le sujet m'int√©ressait particuli√®rement.<br>

Je fais en effet partie d'une association de promotion du v√©lo (La Ville √† V√©lo Lyon M√©tropole) membre de la FUB et soeur de l'association Paris en Selle. Nos associations interviennent r√©guli√®rement aupr√®s des d√©cideurs pour favoriser la transition modale et l'usage du v√©lo en ville en analysant d'un point de vue de l'usager les am√©nagements, en proposant des id√©es √† l'origine d'√©volution (V√©lopolitain √† Paris ou Voies Lyonnaises √† Lyon par exemple) et en participant aux concertations et √©tudes publiques.<br>

Comme Paris, la m√©tropole de Lyon dispose de compteurs Eco-Compteur et mon association a mis en place un site de suivi en temps quasi r√©el de ces compteurs, tout comme peut d'ailleurs le faire Paris en Selle.

J'ai donc convaincu mes coll√®gues de ne pas refaire ce qui √©tait d√©j√† tr√®s bien fait par Paris en Selle <a href="#bib402" class="ref">[4b]</a>et donc de ne pas "cloner" ces visualisations et de travailler sur une approche d'analyse allant au del√† du simple "je constate une hausse √† tel endroit" mais d'aider √† analyser les besoins.

### I.D. D√©couverte du jeu de donn√©es <a id="ID"></a>

#### I.D.1 Biais et difficult√©s potentielles *a priori* <a id="ID1"></a>

La fiche descriptive du jeu de donn√©e mentionne les informations suivantes :

* **Un** site de comptage peut √™tre √©quip√© d'**un** compteur dans le cas d'un am√©nagement cyclable *unidirectionnel* ou de **deux** compteurs dans le cas d'un am√©nagement cyclable *bi-directionnel*.

* **Le nombre de compteurs √©volue** au fur et √† mesure des am√©nagements cyclables:

 - Certains compteurs peuvent √™tre d√©sactiv√©s pour travaux ou m√™me d√©finitivement... nous verrons dans le <a href="#IIA2">pr√©-processing Power Query</a> que nous avons du effectuer des retraitements pour cette raison ;
 - ou subir ponctuellement une panne;
 - ou tout simplement avoir une date d'installation au cours de la p√©riode.

* Les compteurs sont situ√©s sur des am√©nagements soient mixtes (couloirs bus-v√©lo) soient d√©di√©s aux cyclistes (bandes et/ou pistes cyclables).
 **L'hypoth√®se est faite que l'algorithme de traitement des donn√©es r√©alis√© par les compteurs retire correctement les autres v√©hicules** qui pourraient emprunter ces voies, qu'ils y soient autoris√©s (trotinettes) ou non (deux-roues motoris√©s).

* Le jeu de donn√©e √©tant **mis √† jour quotidiennement**, il n'est pas fig√©.
Pour l'exploration ce n'est pas grave.
 Dans le contexte de notre projet, nous n'avons pas le temps de rendre le rapport dynamique sur la base du dernier jeu publi√©, nous avons donc choisi de figer la p√©riode d'analyse, du 1er septembre 2024 au 30 septembre 2025. Le choix de cette p√©riode nous permet en effet de :
  - travailler sur des mois complets;
  - ne pas √™tre p√©nalis√© par les anomalies de l'√©t√© 2024 li√©es aux restrictions de circulation dans Paris pendant les JO et qui ont fortement impact√©s les d√©placements √† v√©lo dans Paris<a href="#bib202" class="ref">[2b]</a>.

#### I.D.2 Exploration du jeu sur l'OpenData de la ville de Paris. <a id="ID2"></a>

Le jeu de donn√©es est disponible sur l'OpenData de la Ville de Paris [ici](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/information/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name).

Il est possible de naviguer dans les donn√©es directement sur le site et ainsi de se faire une premi√®re id√©e des √©l√©ments.<br>

<div style="text-align:center; margin: 20px 0;">  
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/carte_open_data.png" alt="emplacement des compteurs dans le plan v√©lo 2021-2026" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 2 ‚Äî Emplacement des compteurs dans le Plan V√©lo 2021-2026
    </figcaption>
  </figure>
</div>

En premi√®re approche, nous pouvons ainsi observer la localisation des compteurs et visualiser les photos int√©gr√©es au jeu de donn√©es.<br><br>
Ainsi, nous notons que ces photos, avec un cadrage ress√©r√© sur la boucle de comptage, ne sont pas tr√®s int√©ressantes car elles ne nous apportent rien sur la qualit√© de l'am√©nagement en lui-m√™me, nous ne les conserverons pas, *cf.* <a href="#IIA1">pr√©-processing python</a>.<br>
G√©ographiquement, les compteurs sont principalement situ√©s aux portes (notamment sud) de Paris, sur les ponts (emplacement strat√©gique car difficilement contournables) et sur les grands axes identifi√©s dans le Plan V√©lo 2021-2026.<br>
Nous remarquons que le croisement avec ce jeu de donn√©es est int√©ressant √† √©tudier car il nous informe de la qualit√© de l'am√©nagement en place (v√©lopolitain, r√©seau secondaire... correspondent √† des qualit√©s bien pr√©cises et d√©finies <a href="#bib304" class="ref">[3d], </a><a href="#bib401" class="ref">[4a]</a>) mais que l'analyse avec ce jeu est complexe, nous en rediscuterons dans les <a href="#persp1" >perspectives</a>.

La donn√©e principale √©tant une notion de comptage, on peut en deuxi√®me approche regarder si des variations temporelles sont √† pr√©voir.

<div style="display: table; width: 100%; margin-bottom: 1em;">
  <div style="display: table-cell; width: 45%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/saison.png" alt="Trafic median mensuel entre le 01/09/2024 et 30/09/2025" style="width:100%;">
        <figcaption>
         Figure 3 ‚Äî Effet des saisons sur le trafic median mensuel
        </figcaption>
    </figure>
    </div>
    <div style="display: table-cell; width: 55%; padding-left: 12px; vertical-align: top;">
        Il semble y avoir un effet des <b>saisons</b> avec :
        <ul>
            <li> un creux l'hiver : effet du froid ou des f√™tes de fin d'ann√©es ?
            <li> des pics au printemps et √† l'automne;
            <li> et une l√©g√®re diminution en ao√ªt : effet vacances ou chaleur ?
        </ul>
    </div>
</div>

<div style="display: table; width: 100%; margin-top: -40px; margin-bottom: 1em;">
  <div style="display: table-cell; width: 55%; vertical-align: top; padding-right: 12px;">
    Il semble aussi y avoir un effet du <b>jour de la semaine</b> (ou du caract√®re ouvr√© ou non de ce jour).<br>
    On voit par exemple ci-contre sur le Pont de la Concorde un effet qui semble correspondre aux week-ends.
  </div>
  <div style="display: table-cell; width: 45%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/wejf.png" alt="Flux journalier total sur le Pont de la Concorde du 01/09/2024 au 30/09/2025" style="width:100%;">
        <figcaption>
         Figure 4 ‚Äî Effet des jours ouvr√©s sur le trafic journalier
        </figcaption>
    </figure>
   </div>
</div>

Un des objectif donn√© est √©galement d'analyser les <b>p√©riodes et horaires</b> d'affluence.
Ainsi on observe en semaine (ci-dessous le mardi 17 septembre 2025) un pic autour de 8h le matin et un autre autour de 18h.<br>
*A contrario*, les week-ends (ici les samedi 20 et dimanche 21 septembre 2025), le trafic tend √† former une cloche centr√©e sur la fin d'apr√®s-midi.<br>
On remarque au passage que le cycliste est relativement noctambule et que les d√©placements se poursuivent toute la nuit (avec un pic √† la fermeture des bars).

<div style="text-align:center; margin: 20px 0;">  
  <figure style="display:inline-block; width:40%; margin:0 1%;">
    <img src="images/horaire.png" alt="trafic cycliste moyen le mardi 17 septembre 2025 √† Paris" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 5 ‚Äî Pics d'affluence un jour ouvr√©
    </figcaption>
  </figure>
  <figure style="display:inline-block; width:50%; margin:0 1%;">
    <img src="images/horaire_we.png" alt="trafic cycliste moyen les samedi 20 et dimanche 21 septembre 2025 √† Paris" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 6 ‚Äî Pics d'affluence les week-ends
    </figcaption>
  </figure>
</div>

La difficult√© d'interpr√©tation d'une variation dans les comptages et du niveau de fr√©quentation des compteurs nous semble probl√©matique par rapport √† notre objectif de fournir de quoi d√©cider d'un am√©nagement en effet, avoir un trafic faible ou au contraire, qu'est-ce que cela veut vraiment dire ?<br>

Compte-tenu de notre objectif d'analyser √©galement les **zones** d'affluence, il pourra √™tre int√©ressant de comparer les compteurs entre-eux :

* les compteurs **sur-performant** pouvant √™tre interpr√©t√©s comme :
  - des zones o√π les am√©nagements fonctionnent pour favoriser la transition modale sans n√©cessiter d'action √† pr√©voir pour la Mairie de Paris si ce n'est de continuer de suivre leur fr√©quentation ?
  - ou bien des zones o√π les am√©nagements saturent et sont peut-√™tre sous-dimensionn√©s et qu'il est tempts de revoir l'am√©nagement cyclable ?

* les compteurs **sous-performant** pouvant √©galement √™tre interpr√©t√©s comme situ√©s dans des zones o√π des am√©nagements cyclables sont n√©cessaires pour encourager le d√©veloppement du trafic cycliste... ou peut √™tre que l'am√©nagement existant est mal adapt√©, inutile....<br>

Les variations de trafic ne sont pas non plus faciles √† interpr√©eter : traduisent-elles un effet de la qualit√© de l'am√©nagement ou d'un autre facteur ?<br>

Pour r√©pondre √† ces questions, il nous faut des variables explicatives... mais notre jeu de donn√©e n'en dispose que d'une seule : l'heure et la date du comptage.<br><br>

L'exploration nous a permis de voir des variations horaires mais aussi saisionni√®res... cela nous pousse √† regarder du c√¥t√© de la m√©t√©o : si les conditions climatiques sont plus cl√©mentes, la mobilit√© √† v√©lo augmente-t-elle ? et si oui, est-ce partout la m√™me chose ou des lieux y sont-ils plus sensibles ?<br>
Il faut noter d'ailleurs que dans son rapport d‚Äôanalyse de fr√©quentation<a href="#bib201" class="ref">[2a]</a>, la Ville de Paris met sur le compte de la forte pluviom√©trie de 2024 (900 mm sur l‚Äôann√©e) la stagnation de la fr√©quentation par rapport √† 2023, mais cela touche-t-il tous les sites de la m√™me mani√®re et la pluie est-elle toujours le facteur le plus explicatif ?<br><br>

Pour expliquer les variations qui seraient li√©s √† la **qualit√©** de l'am√©nagement cyclable, nous avons besoin d'une variables explicative, l'opportunit√© de la sortie, le 1er octobre, du jeu de donn√©esdes [r√©sultats du Barom√®tre Parlons V√©lo 2025](https://opendata.parlons-velo.fr/) qui identfie notamment la position GPS des points √† am√©liorer en priorit√© selon les cyclistes interrog√©s au printemps 2025 (donn√©es explorables en direct [ici](https://www.barometre-velo.fr/2025/carte/#12.27/48.85887/2.34703).)<br><br>

Cette premi√®re analyse nous conduit donc √† la d√©cision d'enrichir notre jeu de donn√©es avec 2 jeux de donn√©es compl√©mentaires issus des sources suivantes :

* le jeu de donn√©e des [r√©sultats du Barom√®tre v√©lo 2025](https://opendata.parlons-velo.fr/) de la F√©d√©ration des Usagers de la Bicyclette (FUB), paru ce 1er octobre 2025 et qui recense les r√©sultats de la derni√®re enqu√™te d'usage (r√©alis√© au printemps 2025), avec notamment les identifications, par les usagers de zones d'am√©nagements √† am√©liorer ("points rouges") et de zones sur lesquels les am√©nagements ont √©t√© am√©lior√©s depuis 2021 (date de l'enqu√™te pr√©c√©dente, "points verts") ainsi que de points sur lesquels il existe des attentes en mati√®re d'√©quipement (notamment stationnement ("points bleus")).<br>
Chacun de ces points ayant √©t√© √©ventuellement regroup√©s en "clusters" lorsque 14 points sont identifi√©s par les r√©pondants dans une zone de 50m sur une m√™me rue, un m√™me carrefour, une zone a √©t√© trac√©e. Les donn√©es textuelles (commentaire individuels des sond√©s) associ√©s √† chaque point g√©ographique pourront √©ventuellement √™tre utilis√© pour affiner l'analyse.<br>
Ces jeux permettront d'enrichier la table des sites de comptage afin de croiser les analyses avec une cartographie pr√©cise.<br><br>

* les donn√©es m√©t√©o quotidiennes (on a vu lors du rapport de d√©couverte que certaines semaines semblent plus faibles que d'autres en p√©riode hivernale) : on pourra utiliser le [jeu de donn√©e m√©t√©o des 6 capteurs m√©t√©o de la capitale](https://www.data.gouv.fr/api/1/datasets/r/aba837dc-fc7c-4010-ab5e-0eb02feb0010) pour r√©f√©rence.

<hr class="page-break">

### I.E. Bilan de l'√©tape de d√©couverte des donn√©es

√Ä l'issue de cette √©tape, nous d√©cidons de centrer notre analyse sur une visualisation graphique : 
* **temporelle** centr√©e sur l'heure de la journ√©e, le jour de la semaine ainsi que la m√©t√©o
* **g√©ographique** avec une cartographie des zones les plus fr√©quent√©es, √† croiser avec le ressenti des cyclistes en mati√®re de qualit√© d'am√©nagement (nuage de mot).<br><br>

Nous compl√©terons d'une analyse de l'effet de la m√©t√©o et ses diff√©rentes composantes (temp√©rature, pluviom√©trie, vent) et de son effet sur le flux de cycliste.<br>
Nous essaierons de mesurer son effet sur les zones de comptage : les cyclistes √©vitent-ils certains secteurs les jours de pluie (effet de qualit√© du rev√™tement (pav√©...)) ou au contraire en p√©riode de forte chaleur (rev√™tement √† fort albedo, absence d'ombre ?)<br><br>

## II. Pr√©-processing

### II.A. Pr√©processing du jeu principal avec Python <a id="IIA"></a>

#### II.A.1. Exploration d√©taill√©e des jeux de donn√©es 'comptage & compteurs' <a id="IIA1"></a>

Pour explorer le jeu de donn√©es, il faut d'abord y acc√©der... Pandas montre ici ses limites sur un jeu de donn√©es de 1,44 Go : en fonction de la configuration de nos ordinateurs, nous ne sommes que 2 sur 3 √† pouvoir charger un dataframe avec la m√©thode `pandas.read_csv()`.<br>
Nous aurions pu basculer sur une autre librairie mais nous avons simplement opt√© pour un chargement "par morceaux" du jeu de donn√©es via une boucle de d√©coupe par lot de 200 000 lignes puis un regroupement des donn√©es.<br><br>

Une fois le dataframe cr√©√©, nous avons √©tudi√© ses diff√©rentes colonnes en cr√©ant une fonction d'analyse de ces derni√®res et en √©crivant le r√©sultat de cette analyse dans un fichier de m√©tadonn√©es. La fonction est pr√©sent√©e en <a href="#ann2">Annexe 2</a> et son r√©sultat sur le jeu de donn√©e principal en <a href="#ann2a">Annexe 2a</a>.<br><br>

Il est utile de remaquer √† ce stade le fait que la d√©nomination des colonnes, quoique parfois un peu longue, est explicite, avec des identifiants clairement identifiables ce qui simplifie l'utilisation du jeu.<br><br>

Ces informations nous permettent de voir que les donn√©es brutes issues des capteurs sont relativement compl√®tes, mais pas imm√©diatement exploitables.  <br>
Certaines colonnes contiennent plusieurs informations (comme la date et l‚Äôheure combin√©es ou les coordonn√©es g√©ographiques sous forme de texte), tandis que d‚Äôautres sont purement illustratives (notamment la partie photo que nous avions d√©j√† d√©cid√© d'√©carter).<br><br>

Un travail de pr√©-traitement est donc n√©cessaire pour rendre les variables :
- plus **claires**,
- plus **structur√©es**,
- et plus **pertinentes** pour l‚Äôanalyse m√©tier.<br><br>

La pr√©sence de quelques donn√©es manquantes (moins de 4% des lignes √©tant concern√©e) n√©cessitait une analyse compl√©mentaire pour savoir ce que nous allions faire, nous avons donc r√©alis√© une visualisation de ces donn√©es manquantes afin de mieux cerner leur origine:

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/heatmap_manquants.png" alt="donn√©es manquantes dans le jeu principal" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 7 ‚Äî Visualisation des donn√©es manquantes par lignes et colonnes dans le jeu de donn√©e principal
    </figcaption>
  </figure>
</div>

On constate que les donn√©es manquantes sont concentr√©es sur certaines lignes mais concernent la majorit√© des colonnes d'informations.
2 types de profils de manquants apparaissent :

1. Lorsque l'identifiant du compteur est absent, il manque toutes les donn√©es d'informations du compteur et les comptages correspondants (qui par ailleurs sont vides) ne seront pas exploitables : nous pourrons donc supprimer ces lignes.
2. Lorsque l'identifiant du compteur est pr√©sent MAIS que l'ID Photos est absent, alors on a malgr√© tout les informations principales de disponibles, et notamment celles de comptage et de g√©olocalistion des compteurs => il sera donc possible de conserver ces lignes de comptages.<br>

Compte-tenu de ces constatations, il est conclu qu'il sera judicieux de nettoyer les donn√©es APRES avoir s√©par√© les donn√©es en 2 jeux distincts (comptage et compteurs) et supprimer les colonnes inutiles de photos.<br><br>

Il faut note que le jeu ne pr√©sente aucune ligne en doublon.<br>
La structure du jeu, issue d'une jointure entre les donn√©es de comptage fournies par Eco-Compteur et les donn√©es d'identification et localisation des compteurs, conduit par contre √† une multiplication d'information li√©es √† ces compteurs : on s'attend √† avoir les informations relatives √† chaque compteurs pour les 24h de chacune des 395 jours de comptage soit 9480 lignes potentielles lorsque le compteur n'a pas subi d'interruption.<br><br>

Cela alourdit le dataframe et justifie d'autant plus la scission avec un jeu "donn√©es de faits" pour les donn√©es de comptage et "donn√©es dimensionnelles" pour les donn√©es des compteurs.<br>
Nous en profiterons pour scinder la colonne de coordonn√©es g√©ographique afin de r√©cup√©rer la latitude et la longitude, format plus pratique pour le visualisation dans Power BI et basculerons les donn√©es temporelles au format datetime.<br>

#### II.A.2. Pr√©paration du jeu principal <a id="IIA2"></a>

##### II.A.2.a. Pr√©paration du jeu principal

Cette pr√©paration s'est d√©roul√©e en plusieurs √©tapes, principalement dans le Jupyter Notebook nomm√© `rapport_d_exploration.ipynb`.

1. **S√©paration des colonnes composites, conversion des types de donn√©es et extraction des coordonn√©es g√©ographiques**  

* Conversion des dates en format `datetime`, des coordonn√©es en `float`, et que les nombres de comptages sont bien de type `int`.

* Conversion du champ `Date et heure de comptage` du format 'object' en format `datetime` en prenant en compte le fuseau horaire parisien et cr√©ation des champs de `Date` et `Heure`pour faciliter les regroupements temporels :
  - `Date` (pour l‚Äôanalyse par jour, mois, saison)
  - et `Heure` (pour les pics horaires)
Apr√®s tergiversations, nous avons finalement choisi de conserver n√©anmoins la colonne au format 'datetime' initial car elle sera utile dans l'utilisation ult√©rieure sur PowerBi (cr√©ation de hi√©rarchie temporelle jusqu'√† l'heure).

* Transformation de la colonne `Coordonn√©es g√©ographiques` du jeu de donn√©es des compteurs en deux variables num√©riques distinctes `latitude` et `longitude` format plus pratique pour les visualisations cartographiques dans Power BI.

2. **Simplification de certains noms de colonnes** pour faciliter les manipulations car certains noms √©taient tr√®s longs.

<table class="table-compact">
  <thead>
    <tr><th>Nom de colonne initial</th><th>Nouveau nom</th></tr>
  </thead>
  <tbody>
    <tr><td>`Comptage horaire`</td><td>`comptage_horaire`</td></tr>
    <tr><td>`Date et heure de comptage`</td><td>`date_heure`</td></tr>
    <tr><td>`Identifiant du compteur`</td><td> id_compteur`</td></tr>
    <tr><td>`Nom du compteur`</td><td>`nom_compteur`</td></tr>
    <tr><td>`Identifiant du site de comptage`</td><td> `id_site`</td></tr>
    <tr><td>`Nom du site de comptage`</td><td>`nom_site`</td></tr>
    <tr><td>`Identifiant technique compteur`</td><td>`id_technique_compteur`</td></tr>
    <tr><td>`Date d\'installation du site de comptage`</td><td>`date_installation`</td></tr>
    <tr><td>`Lien vers photo du site de comptage`</td><td>`photo_site`</td></tr>
    <tr><td>`Coordonn√©es g√©ographiques`</td><td>`coordonnees`</td></tr>
  </tbody>
</table>

3. **Correction du format de l'identifiant du site de comptage :** sur certaines lignes, le site de comptage pr√©sentait une alt√©ration du format avec pr√©sence de virgule. Nous avons donc supprim√© ces derni√®res et converti en entier pour avoir un format coh√©rent avec la nature d'identifiant de la colonne.

##### II.A.2.c. Extraction du jeu de comptage

Sur le jeu de donn√©e de comptage, nous avons conserv√© les colonnes suivantes:
   * `id_compteur`
   * `id_site`
   * `comptage_horaire`
   * `date_heure`
   * `mois_annne_comptage`
   * `date`
   * `heure`

Il faut noter que bien que nous ayons une relation de type *One to Many* entre l'identifiant du site de comptage et l'identifiant du compteur (un compteur n'appartient jamais qu'√† un seul site de comptage, et il y a fr√©quemment 2 compteurs (1 dans chaque direction) pour un m√™me site), nous avons sciemment choisi de conserver l'identifiant du site de comptage dans notre jeu de donn√©es alors que nous aurions pu l'√©liminer.<br>
Cependant, √† ce stade de notre √©tude, nous ne savions pas si nous allions nous focaliser sur les sites de comptage ou les compteurs dans notre analyse : nous avons donc d√©cider de conserver cette colonne.<br><br>

Le jeu ainsi cr√©√© ne contenait ni doublon ni manquant et ne n√©cessitait donc pas de nettoyage suppl√©mentaire.<br><br>

A l'issu de cette √©tape, nous avons donc cr√©√© un fichier `comptage-velo-donnees-compteurs-allege.csv` dans notre r√©pertoire \data\processed et un fichier de m√©tadonn√©es `metadatas-donnees-comptage.txt` dans note r√©pertoire \references.

##### II.A.2.b. Extraction du jeu de compteur

Bien que certaines colonnes (photos notamment) aient √©t√© identifi√©s comme inutiles lors de l'√©tape de d√©couverte, certains membres du groupe n'ont pas voulu les √©liminer √† ce stade "au cas o√π elles seraient utiles plus tard", nous avons donc repris l'ensemble des colonnes et simplement √©cart√© la colonne de comptage et celle de date-heure m√™me si seules les informations g√©ographiques et les couples id_compteur et id_site associ√©s √† leurs noms nous aient finalement √©t√© utiles.<br><br>

Une fois les nombreux doublons supprim√©s, il restait quelque valeurs manquantes mais uniquement sur des colonnes qui ne nous int√©ressait pas (photos) et nous n'avons donc pas cherch√© √† les remplacer.

#### II.A.3. G√©olocalisation des compteurs  <a id="IIA3"></a>

Nous avons cherch√© √† situer nos compteurs sur une carte, ceci afin de pouvoir valider ult√©rieurement l'int√©r√™t de croiser ou non ces positions avec celles des commentaires du barom√®tre FUB.<br>
Pour cela, si nous avions effectivement cr√©√© une colonne de `latitude` et `longitude` pour faciliter l'usage dans Power BI, nous avons pr√©f√©r√© opter pour la cr√©ation d'une colonne de type GEOMETRY pour une visualisation Python avec `geopandas`. Nous avons donc cr√©√© un point g√©ographique √† partir des coordonn√©es pour cr√©√© un GeoDataFrame.<br>
Pour cette visualisation, nous avons utilis√© le syst√®me de r√©f√©rence de coordonn√©es (CRS) du syst√®me GPS en latitude/longitude en WGS84. Nous avons donc utilis√© la projet "EPSG:4326" et nous avons stock√© ce point dans un champ nomm√© `geometry`.<br><br>

A l'issu de cette √©tape, nous avons cr√©√© un fichier `compteurs_velo.csv` dans notre r√©pertoire \data\processed et un fichier de m√©tadonn√©es `metadatas-donnees-compteur.txt` dans note r√©pertoire \references.<br><br>

La cr√©ation de ce point g√©ographique m'a permis ensuite de positionner chaque compteur sur une carte de Paris dynamique avec la librairie folium (cf. rapport d'exploration), carte que nous avons mise de c√¥t√© pour superposer plus tard avec les avis des cyclistes.<br>
<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/carte_compteurs.png" alt="emplacement des compteurs" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 8 ‚Äî Emplacement des compteurs
    </figcaption>
  </figure>
</div>

#### II.B. Exploration et Pr√©processing des jeux d'enrichissement avec Python  <a id="IIB"></a>

##### II.B.1 Jeu de donn√©es m√©t√©orologique <a id="IIB1"></a>

L'exploration et la pr√©paration du jeu de donn√©e m√©t√©o a √©t√© faite dans un Jupyter Notebook nomm√© `m√©teo.ipynb`.<br><br>

Le jeu de donn√©es t√©l√©charg√© `Q_75_latest-2024-2025_RR-T-Vent.csv` contenait l'int√©gralit√© des donn√©es de 2024 et 2025, soit 3875 lignes et 57 colonnes. nous avons donc commenc√© par le **restreindre √† la m√™me plage de date** que notre jeu de comptage soit du 01/09/2024 au 30/09/2025.<br><br>

D'autre part, le jeu de donn√©e correspondait aux r√©sultats de **6 capteurs** m√©t√©o de la capitale.<br>
Nous avons consid√®r√© ces 6 stations m√©t√©o comme compl√©mentaires : s'il y a quelque diff√©rence d'altitude entre la Tour Eiffel et les jardins du Luxembourg, il n'y a cependant pas de diff√©rences climatiques significatives par rapport √† notre analyse. Nous avons donc agr√©g√© les donn√©es en prenant la **moyenne** des non nuls pour chaque param√®tre n'identifiant pas le capteur.<br><br>

Nous avons ensuite cherch√© √† **supprimer les colonnes** ne nous int√©ressant pas.<br>
Pour cela nous avons consult√© la notice en ligne du jeu de donn√©e afin de comprendre les intitul√©s peu explicites pour les non m√©t√©orologues : il s'est av√©r√© que toutes les colonnes commen√ßant par la lettre 'Q' √©taient des colonnes techniques qualifiant le niveau de qualit√© de la mesure et non la mesure elle-m√™me, nous pouvions donc les √©liminer.<br>
L'analyse des **manquants** nous a par ailleurs permis de supprimer d'autres colonnes, int√©gralement vides car ne correspondant tout simplement pas au climat parisien sur notre p√©riode.<br>
Il nous restait alors une s√©rie de colonne que nous avons pu renommer avec leur d√©finition respectives plut√¥t que leurs abbreviations anglosaxonnes:

<table class="table-compact">
  <thead>
    <tr><th>Nom de colonne initial</th><th>Nouveau nom</th></tr>
  </thead>
  <tbody>
    <tr><td>RR</td><td>RR pr√©cipitations (mm)</td></tr>
    <tr><td>DRR</td><td>DRR dur√©e de pr√©cipitations (mn)</td></tr>
    <tr><td>TN</td><td>TN temp. mini (¬∞C)</td></tr>
    <tr><td>HTN</td><td>HTN heure la + froide (hhmn)</td></tr>
    <tr><td>TX</td><td>TX temp. max (¬∞C)</td></tr>
    <tr><td>HTX</td><td>HTX heure la + chaude (hhmn)</td></tr>
    <tr><td>TNTXM</td><td>TNTXM temp. moyenne quotidienne (¬∞C)</td></tr>
    <tr><td>TAMPLI</td><td>TAMPLI amplitude thermique (¬∞C)</td></tr>
    <tr><td>TNSOL</td><td>TNSOL temp. mini √† 10cm du sol (¬∞C)</td></tr>
    <tr><td>TN50</td><td>TNSOL temp. mini √† 50cm du sol (¬∞C)</td></tr>
    <tr><td>DG</td><td>DG dur√©e de gel sous abri (mn)</td></tr>
    <tr><td>FFM</td><td>FFM force moyenne sur 10mn du vent √† 10m (m/s)</td></tr>
    <tr><td>FF2M</td><td>FF2M force moyenne sur 10mn du vent √† 2m (m/s)</td></tr>
    <tr><td>FXY</td><td>FXY force max du vent moyen sur 10mn √† 10m (m/s)</td></tr>
    <tr><td>DXY</td><td>DXY direction du vent moyen √† 10m (rose de 360)</td></tr>
    <tr><td>FXI</td><td>FXI force max instantan√©e du vent √† 10m (m/s)</td></tr>
    <tr><td>HXI</td><td>HXI heure du vent max instantan√©e √† 10m (hhmm)</td></tr>
    <tr><td>DXI</td><td>DXY direction du vent max instantan√©e √† 10m (rose de 360)</td></tr>
    <tr><td>FXI2</td><td>FXI force max instantan√©e du vent √† 2m (m/s)</td></tr>
    <tr><td>HXI2</td><td>HXI heure du vent max instantan√©e √† 2m (hhmm)</td></tr>
    <tr><td>DXI2</td><td>DXY direction du vent max instantan√©e √† 2m (rose de 360)</td></tr>
    <tr><td>FXI3S</td><td>FXI3S force max quotidienne sur 3sec du vent √† 10m (m/s)</td></tr>
    <tr><td>HXI3S</td><td>HXI3S heure du vent max sur 3 sec √† 10m (m/s)</td></tr>
  </tbody>
</table>

Cela fait encore beaucoup de colonnes. Nous avons d√©cid√© malgr√© tout de nous arr√™ter l√† pour le nettoyage avec Python, l'id√©e √©tant de r√©fl√©chir √† un indicateur simplifi√© et de finaliser le retraitement <a href="#IIB4">avec Power Query</a> et <a href="#IIC4">DAX</a> afin de b√©n√©ficier des outils de visualisations de Power BI pour identifier les √©ventuelles colonnes calcul√©es ou mesures susceptibles de faciliter l'analyse visuelle.<br><br>

A l'issu de cette √©tape, nous avons donc cr√©√© un fichier `meteo.csv` dans notre r√©pertoire \data\processed et un fichier de m√©tadonn√©es `metadatas-donnees-meteo.txt` dans notre r√©pertoire \references.

##### II.B.2. Jeu de donn√©es de l'enqu√™te de la FUB <a id="IIB2"></a>

Apr√®s en avoir fait la demande aupr√®s de la FUB, nous avons pu t√©l√©charger les jeux de donn√©es du barom√®tre 2025 pour la ville de Paris. La notice du jeu de donn√©es est pr√©sent√©e en <a href="#ann2c">Annexe 2c</a>. <br>
Dans le cadre de notre projet, nous avons uniquement utilis√© les fichiers `.geojson` contenant les descriptions donn√©es par les r√©pondant pour chacun des points (max 9) qu'ils avaient pu identfier.<br><br>

Deux types de fichiers .geojson √©taient disponibles :

* les 3 fichiers **de clusters**, issu du pr√©traitement de la FUB et correspondant √† un regroupement de points identifi√©s par les r√©pondants, ces clusters formant des "zones prioritaires". √Ä noter que les fichiers de cluster pour la ville de Paris √©tant vide (erreur de cr√©ation ?), nous nous sommes rabattus sur les fichiers de clustering du d√©partement 75.
* les 3 fichiers correspondants √† chacune des cat√©gories **de points** (vert, rouge, bleu). Ces fichiers √©tant naturellement plus complets que les fichiers de clusters puisque exhaustif.<br><br>

Dans un premier temps, nous avons commenc√© notre exploration par les donn√©es de clustering, pour voir si les zones identifi√©s (m√©thode expliqu√©e dans la notice de la FUB et script en libre acc√®s sur [GitHub](https://github.com/dataforgoodfr/offseason_fub)) √©taient ou non √† proximit√© de nos compteurs afin de nous assurer de la pertinence du croisement des jeux de donn√©es.<br>

L'exploration et la pr√©paration du jeu de donn√©e a √©t√© faite dans un Jupyter Notebook nomm√© `barometre2025.ipynb` ainsi que dans `rapport_d_exploration.ipynb`.

###### II.B.2.a. Exploration des clusters du barom√®tre FUB <a id="IIB2a"></a>

Dans un premier temps, nous avons regroup√© les 3 fichiers de clusters .geojson en un unique GeoDataFrame, avec l'ajout d'un champ `cat√©gorie` permettant d'identifier le type de cluster (rouge, vert ou stationnement).
Nous avons √©galement supprim√© les colonnes qui ne nous int√©ressait pas : `commune`,`epci`,`departement`,`region`... en effet, 3 de ces colonnes n'avaient qu'une seule modalit√© et m√™me si nous aurions pu chercher √† int√©grer une dimension de num√©ro d'arrondissement (*via* le num√©ro insee de la commune) dans notre hi√©rarchie g√©ographique "site de comptage > compteur", cela ne nous a pas paru utile √† notre analyse, celle-ci √©tant destin√©e √† la mairie "centrale" de Paris en tant que d√©cisionnaire et non aux mairies d'arrondissement.<br><br>

<div style="display: table; width: 100%;">
  <div style="display: table-cell; width: 55%; vertical-align: top; padding-right: 12px;">
  Sur ce GeoDataFrame, nous √©tions confront√© au format sp√©cifique des polygones des clusters (avec une liste des points d√©finissant la zone), comme par exemple :<code>MULTIPOLYGON (((2.285062579 48.880798105, 2.284173146 48.880794376, 2.283934653 48.881017294, 2.284509497 48.881230919, 2.285062579 48.880798105)))</code> que nous cherchions √† superposer sur notre <a href="#IIA3">carte des compteurs</a>.<br>
  Avec la librairie <code>shapely</code>, j'ai pu travailler sur la cr√©ation de cette superposition dont une partie du script est en <a href="#ann3">Annexe 3</a>.
  </div>
  <div style="display: table-cell; width: 45%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/carte_compteurs+clusters.png" alt="emplacement des compteurs et clusters" style="width:100%;">
        <figcaption>
         Figure 9 ‚Äî Superposition des compteurs et clusters barom√®tre FUB 2025
        </figcaption>
    </figure>
   </div>
</div>

###### II.B.2.b. 2√®me phase de l'exploration g√©ographique du barom√®tre FUB <a id="IIB2b"></a>

Cette superposition des donn√©es compteurs et clusters de commentaires nous semblait assez faible.Mohammed et Ghizlane ont donc affin√© le script pour d√©terminer combien de compteurs se trouvaient dans un polygone identifi√©s par le barom√®tre en travaillant sur le notebook `jointure_spacialeV1.ipynb`.<br>
Pour cela, ils ont utilis√©s la m√©thode `geopandas.sjoin()` avec l'argument `predicate='within'` qui a permis de cr√©er une carte des sites se trouvant dans un cluster vert, une autre pour ceux (√©ventuellement les m√™mes) se trouvant dans un cluster rouge en encore dans un bleu.<br>
Ceci a permis d'aboutir √† la carte suivante ci-dessous.

<div style="text-align:center; margin: 20px 0;">  
  <figure style="display:inline-block; width:45%; margin:0 1%;">
    <img src="images/sites_dans_clusters.png" alt="compteurs dans clusters" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 10 ‚Äî Sites de comptage √† l'int√©rieur d'un cluster du barom√®tre FUB 2025
    </figcaption>
  </figure>
  <figure style="display:inline-block; width:45%; margin:0 1%;">
    <img src="images/points.png" alt="emplacement commentaires FUB 2025" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 11 ‚Äî Emplacement des compteurs et commentaires verts ou rouges du barom√®tre FUB 2025
    </figcaption>
  </figure>
</div>

La confirmation du faible nombre de compteur √† l'int√©rieur d'un cluster √©tant faite, nous avons donc d√©cid√© d'utiliser directement les donn√©es d√©taill√©es du barom√®tres (fichiers "points") car ceux-ci √©taient nettement plus nombreux (> 23 000) et dispers√©s, y compris √† proximit√© des compteurs comme on peut le voir sur la carte ci-dessus.

N√©anmoins, le fait de basculer sur le jeu complet de commentaire impliquait que nous allions traiter nettement plus de donn√©es et donc devoir d√©velopper notre propre script de clustering afin de rapprocher les commentaires des sites de comptage. Nous le verrons <a href="#IIB4">plus loin</a>.

##### II.B.3. Pr√©paration des avis pour l'analyse textuelle <a id="IIB3"></a>

A l'issue de l'√©tape pr√©c√©dente, nous avons donc d√©cid√© de retenir les 3 fichiers de points .geojson comme source de commentaires.
Comme pour les clusters, nous avons donc retrait√© ces fichiers afin de ne conserver que la colonne de `description` et celle de `geometry` et nous avons concat√©ner les 3 fichiers en un unique dataframe muni d'une colonne `categorie`pour identifier la source de donn√©es.<br>
Mais les descriptions fournies par les r√©pondants √† l'enqu√™te ne sont pas exploitables directement en l'√©tat : la longueur du texte et le nombre de lignes obligent √† traiter ces donn√©es pour en extraire les id√©es principales.<br><br>
Nous avons donc d√©cid√© de mettre en place une visualisation de ces id√©es par nuages de mots, l'objectif √©tant de d√©finir un script r√©utilisable dans Power BI pour associer un nuage de mot √† chaque compteur et en identifier la tonalit√© principale (plut√¥t des avis positifs ou n√©gatifs ?).

###### II.B.3.a. Normalisation et lemmatisation du texte en fran√ßais <a id="IIB3a"></a>

Le d√©tail du script utilis√© √† cette √©tape est disponible en <a href="#ann4a">Annexe 4a</a>.<br>

L'objectif premier consiste √† conserver les id√©es, la notion de leurs fr√©quences et se d√©barasser de l'inutile.

Pour cela nous avons d√©fini une fonction nous permettant de :

* tok√©niser nos commentaires pour les analyser √† la maille du "mot" et non de la phrase compl√®te. C'est la fr√©quence des mots dans les commentaires qui nous donnera une information.

* utiliser une liste de "stop words" pour all√©ger ces commentaires
  - supprimer les mots "vides" n'apportant pas d'information (d√©terminants, pr√©positions...)
  - supprimer les mots de 2 caract√®res et moins (certains mots de 3 lettres √©tant pertinents dans notre contexte, par exemple le mot "bus")
  - supprimer des mots, fr√©quents dans notre jeux de donn√©e mais trop impr√©cis pour √™tre pertinent pour notre analyse ("v√©lo","rue"...)

* effectuer une lemmatisation morphologique et syntaxique des cha√Ænes de caract√®res afin d'aller "√† l'essentiel"

Et nous avons ensuite appliquer cette fonction √† la colonne `description`de notre dataframe pour stocker la cha√Æne lemmatis√©e ainsi obtenue dans une nouvelle colonne `commentaire` de notre dataframe.

Lorsque j'ai travaill√© sur cette √©tape, j'ai √©t√© rapidement confront√© √† un d√©tail : la bilioth√®que utilis√©e dans le cours (wordnet.lemmatizer) √©tait totalement inadapt√©e au fran√ßais et je n'obtenais pas les r√©sultats attendus. Apr√®s recherches sur StackOverflow, mon choix s'est port√©e sur la biblioth√®que `spaCy`.
Cette derni√®re dispose de plusieurs mod√®les de lemmatisation existent, nous avons retenu le pipeline pr√©-entra√Æn√© de taille moyenne (md=medium) `fr_core_news_md` qui a l'avantage d'√™tre l√©ger √† installer.<br><br>

Apr√®s quelques tests, nous avons cependant constat√© que spaCy ne suffirait pas car il n'y avait notamment pas de distinction entre les formes masculin et f√©minin des adjectifs. Apr√®s analyse de la [documentation](https://spacy.io/models/fr), c'est parce que spaCy une lemmatisation **morphologique** (sur les r√®gles de la langue) et non **s√©mantique** (sur le sens) : il va remplacer les verbes conjuger par leur infinitif et supprimer la plupart des pluriels pour les mettre au singulier mais conserver les distinctions de genres des noms et adjectifs.<br> Pour corriger cette limite, nous avons utilis√© un module compl√©mentaire de spaCy, `spaCy-lefff`(pour Lefff = **Le**xique des **f**ormes **f**l√©chies du **f**ran√ßais)
A noter qu'on aurait aussi pu choisir d'utiliser une m√©thode de regroupement par proximit√© s√©matique mais que nous n'avons pas juger utile de se lancer dans quelque chaose d'aussi d√©taill√© pour nos commentaires.<br><br>

Une fois les descriptions ainsi lemmatis√©e, nous avons stock√© notre dataframe dans un fichier `commentaires.csv` dans notre r√©pertoire \data\processed et un fichier de m√©tadonn√©es `metadatas-donnees-meteo.txt` dans notre r√©pertoire \references.

###### II.B.3.b. Cr√©ation d'un nuage de mot suivant 2 algorithmes diff√©rents <a id="IIB3b"></a>

√Ä ce stade, nous disposions donc d'un jeu de commentaire et notre objectif √©tait de d√©finir un script permettant de faire ressortir un nuage de mot cr√©√© avec la librairie `WordCloud` √† partir d'un √©chantillon de plusieurs avis, l'objectif *in fine* √©tant de pouvoir d√©couper notre jeu de commentaire selon proximit√© avec un compteur.

Deux visualisations ont √©t√© test√©es :

1. utilisation d'un wordcloud simple directement √† partir des cha√Ænes lemmatis√©es

2. utilisation d'un wordcloud apr√®s application d'un algorithme de bag of word bas√© sur un score de TF_IDF pour voir si les mots mis en avant sont plus pertinents.

Le rapprochement des commentaires avec le site de comptage le plus proche n'√©tant pas pr√™t au moment o√π nous faisions ces tests, ceux-ci ont √©t√© effectu√©s sur la base de la cat√©gorisation "rouge"/"vert" du commentaire. La cr√©ation d'un corpus de commentaires (en listant ces derniers) plut√¥t qu'en les concat√©nant permet d'exploiter les variations de fr√©quence de commentaire d'un cycliste √† un autre.

Le d√©tail du script utilis√© √† cette √©tape est disponible en <a href="#ann4b">Annexe 4b</a>.<br>

Il convient de noter que l'utilisation de l'algorithme TF_IDF n√©cessite l'utilisation de modules suppl√©mentaires et surtout la suppression des accents dans le texte

###### II.B.3.c. Choix de l'algorithme le plus pertinent <a id="IIB3c"></a>

Nos essais nous ont permis d'obtenir, avec le m√™me jeu de donn√© lemmatis√©e, les 2 s√©ries de nuages de mots ci-dessous.

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/nuages1.png" alt="Nuages de mots bas√© sur les r√©p√©titions" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 12 ‚Äî Nuages de mots bas√© sur les r√©p√©titions
    </figcaption>
  </figure>
</div>

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/nuages2.png" alt="Nuages de mots apr√®s application de l'algorithme TF_IDF" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 13 ‚Äî Nuages de mots apr√®s application de l'algorithme TF_IDF
    </figcaption>
  </figure>
</div>

On peut noter la disparition des accents dans la 2√®me s√©rie de nuages, effet collat√©ral de l'application de la fonction de suppression des accents qui √©taient rendus n√©cessaires si nous ne voulions pas maximiser les scores des mots accentu√©s. Mais visuellement, cela n'est finalement pas tr√®s d√©rangeant.<br>
On remarque √©galement que les mots "piste" et "am√©nagement" remontent beaucoup et seront probablement √† ajouter √† notre liste de mot vide dans notre script final  (s'appliquant au corpus des avis par proximit√© avec nos sites de comptage).<br><br>

La diff√©rence entre les deux s√©ries de nuage de mot n'est pas flagrante. Cependant, l'algorithme TF_IDF semble remonter des mots un peu plus pr√©cis et nous d√©cidons donc de conserver ce dernier pour la suite du projet.<br>

##### II.B.4. Jointure g√©ospatiale des avis <a id="IIB4"></a>

L‚Äôobjectif de cette √©tape √©tait de lier spatialement les ressentis exprim√©s par les usagers (commentaires du barom√®tre FUB) aux sites physiques de mesure des flux cyclistes.
Mais un commentaire √† 300m d'un compteur est-il pertinent pour notre analyse ?
Probablement pas, c'est pourquoi, il √©tait n√©cessaire de d√©terminer le rayon maximal garantissant que seul les relations spatialement coh√©rentes seraient conserv√©es pour l‚Äôanalyse.

<div style="display: table; width: 100%;">
  <div style="display: table-cell; width: 55%; vertical-align: top; padding-right: 12px;">
  Pour d√©finir ce seuil, nous avons proc√©d√© par √©tapes, l'id√©e √©tant de tracer diff√©rents cercles concentriques autour de nos sites de comptages et de comptabiliser combien de commentaires se trouvaient dans le disque ainsi trac√©. Nous avons donc r√©utilis√© la m√©thode geopandas.sjoin() avec predicate='within' comme lors de la <a href="#IIB2b">phase d'exploration des clusters</a>.
  Le d√©tail du code affin√© par Mohammed est propos√© en <a href="#ann5a">Annexe 5a</a>.
  Ceci nous a permis d'obtenir la courbe ci-contre et de fixer le seuil √† 125m.
  </div>
  <div style="display: table-cell; width: 45%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/proximite.png" alt="D√©termination du rayon de proximit√© seuil" style="width:100%;">
        <figcaption>
         Figure 14 ‚Äî D√©termination du rayon de proximit√© √† retenir.
        </figcaption>
    </figure>
   </div>
</div>

Dans un second temps, nous avons identifi√© syst√©matiquement le **compteur** le plus proche pour chaque commentaire et mesur√© sa distance.
Une colonne `statut_proximite`a ensuite permis de distinguer les correspondances g√©ographiquement pertinentes (retenu - soit environ 10% des commentaires du jeu) de celles jug√©es trop √©loign√©es (non retenu) en fonction de notre seuil de 125m.
Le d√©tail de cette 2√®me partie du script est propos√© en <a href="#ann5b">Annexe 5b</a>.

√Ä l'issue de cette √©tape, nous disposions donc d'un fichier `commentaires_enrichis_sites.csv` dans notre r√©pertoire \data\processed qui se pr√©sentait de la mani√®re suivante :

<table class="table-compact">
  <thead>
    <tr><th>description</th><th>categorie</th><th>commentaire</th><th>site_plus_proche_id</th><th>site_plus_proche_nom</th><th>distance_au_site_m</th><th>compteur_plus_proche_id</th><th>statut_proximite</th></tr>
  </thead>
  <tbody>
  <tr><td>dangereux car les taxis sont en double file sur la piste cyclable</td><td>rouge</td><td>dangereux car taxi double file piste</td><td>100041488</td><td>27 boulevard Diderot</td><td>259.0915002039714</td><td>100041488-101041488</td><td>non retenu</td></tr>
  <tr><td>Voitures coupent la priorit√© aux cyclistes</td><td>rouge</td><td>voiture couper priorit√©</td><td>100007049</td><td>28 boulevard Diderot</td><td>86.91463944122768</td><td>100007049-102007049</td><td>retenu</td></tr>
  <tr><td>Passer au feu vert pi√©ton avec son v√©lo √† cet endroit reste une aventure p√©rilleuse. C'est moins pire qu'il y a deux ans mais, entre la circulation dense et les nombreux chauffards, ce croisement reste vraiment dangereux pour les v√©los.</td><td>rouge</td><td>passer feu vert pi√©ton endroit reste aventure p√©rilleux moins pire deux an entrer circulation dense nombreux chauffard croisement reste dangereux</td><td>100047547</td><td>6 rue Julia Bartet</td><td>98.90265675845514</td><td>100047547-104047547</td><td>retenu</td></tr>
  </tbody>
</table>

On remarque que certaines colonnes ne seraient pas n√©cessairement indispensables √† la suite du projet : l'identifiant du compteur est suffisant pour faire la jointure dans le mod√®le de donn√©e Power BI. <br>
Les 2 colonnes li√©es au site de comptage (identifiant et nom) sont en effet l√† uniquement parce que cr√©es lors la phase de calcul : en d√©cidant de rapprocher les commentaires de nos zones de comptage, nous nous √©tions en effet d'abord focaliser sur le site de comptage, consid√©rant le sens comme n'√©tant pas renseign√© dans le commentaire. Mais cela induisait la cr√©ation d'une relation Many to Many dans le mod√®le Power BI et c'est pourquoi nous sommes finalement revenu sur notre script pour rattacher le commentaire √† un compteur.

##### II.B.5. Fichiers obtenus √† l'issu de cette √©tape <a id="IIB5"></a>

√Ä la fin de cette √©tape, nous disposons de plusieurs fichiers csv retrait√©s qui vont nous servir de source dans Power BI :

   - `comptage-velo-donnees-compteurs-allege.csv`;
   - `compteurs_velo.csv`;
   - `meteo.csv`;
   - `commentaires_enrichis_sites.csv`.

#### II.C. Pr√©processing dans Power Query <a id="IIC"></a>

##### II.C.1. Collecte des donn√©es <a id="IIC1"></a>

La premi√®re √©tape de notre cr√©ation de rapport dans Power BI √† consister √† se connecter √† nos donn√©es source et donc √† se confronter √† la difficult√© de leur acc√®s.
Si nous √©tions s√ªr d'avoir besoin d'une connexion en Import comment g√©rer l'emplacement du fichier pour que le rapport fonctionne pour chacun d'entre-nous ? <br>
D'autant qu'au moment o√π nous cr√©√©ions le rapport, les fichiers sources √©taient encore en cours de cr√©ation avec python et donc instables.<br><br>
Pour solutionner ce probl√®me d'acc√®s √† une version stable des fichiers sources, nous avons d√©cid√© d'utiliser GitHub comme un d√©p√¥t pour nos fichiers csv et de nous connecter √† ces fichiers via l'API GitHub.<br>
Pour cela, il a fallu cr√©√©r un token (car le d√©p√¥t est priv√©) et placer ce token dans un param√®tre du rapport (pour ne pas le faire appara√Ætre en clair dans les diff√©rentes requ√™tes Power Query sourcant les donn√©es), *cf.* un exemple dans l'<a href="ann6">Annexe 6</a>.

Malheureusement, √† l'issue de la pr√©paration du jeu de donn√©es de comptage, ce fichier restait trop grand pour √™tre partag√© sur GitHub ou sur nos Google Drive respectifs. Pour ce fichier source l√†, la solution ne fonctionnait donc pas. <br>
Nous avons donc cr√©√© un deuxi√®me param√®tre, correspondant √† l'emplacement, sur chacun de nos pc, du fichier dans notre d√©p√¥t local.<br>
Ainsi, √† l'ouverture du rapport, et sous r√©serve que notre branche locale soit √† jour, il suffit de s√©lectionner le param√®tre correspondant √† notre chemin local pour actualiser le rapport.

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/application_param1.png" alt="Application d'un param√®tre au rapport" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 15 ‚Äî Application d'un param√®tre au rapport
    </figcaption>
  </figure>
</div>

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/application_param2.png" alt="S√©lection du chemin utilisateur" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 16 ‚Äî S√©lection du chemin utilisateur
    </figcaption>
  </figure>
</div>

##### II.C.2. Transformations sur la table des compteurs <a id="IIB2"></a>

Nous <a href="IIA3">'avons vu</a>l'avons vu, le fichier des compteurs pr√©par√© avec Python contenait encore un certain nombre de **colonnes inutiles** pouvant p√©naliser fortement les performances de notre rapport Power BI, et donc l'exp√©rience utilisateur.<br>

Nous utilisons donc Power Query (*cf.* <a href="ann6">Annexe 6</a>) pour √©lminer les champs purement descriptifs (notamment li√©s aux photos qui n'apportaient rien) ou redondantes :

   - `Identifiant technique compteur`,
   - `Date d\'installation du site de comptage`,
   - `Lien vers photo du site de comptage`,
   - `ID Photos`,
   - `test_lien_vers_photos_du_site_de_comptage_`,
   - `id_photo_1`,
   - `url_sites`.

Nous en profitons pour am√©liorer la convivialit√© des noms de colonnes qui avaient √©t√© abr√©g√©es et simplifi√©es pour √™tre manipulable confortablement dans Python : l'objectif cette fois est que les noms de colonnes soient le plus explicites possible pour l'utlisateur final du rapport.<br><br>

Envin, nous avons revu le contenu des champs nommant les sites de comptage et les comptages par leur adresse.<br>
En effet, nous disposons parfois de plusieurs compteurs dans la m√™me rue mais √† des adresses diff√©rentes, par exemple nous avons un site au 44 avenue des Champs Elys√©es SE-NO et un autre au 33 avenue des Champs Elys√©es NO-SE.<br>

Si nous laissions les compteurs nomm√©s de cette mani√®re, alors nous aurions eu dans nos menus d√©roulants une liste tri√©e par num√©ro de rue, ce qui aurait par exemple plac√©s les 2 compteurs du 36 rue de Grenelle ENTRE nos 2 compteurs des Champs Elys√©es et cela aurait √©t√© peu confortable pour l'utilisateur du rapport Power BI.<br>

Pour r√©soudre ce souci, nous avons donc mis en place un renommage des adresses en prenant le contenu √† droite de la premi√®re majuscule situ√© dans la cha√Æne de caract√®re, puis le num√©ro et le type de voie entre parenth√®se. De nombreux compteurs √©tant situ√© sur des ponts, donc sans num√©ro, nous avons du traiter cette exception.

##### II.C.3. Cr√©ation d'un score m√©t√©o <a id="IIC4"></a>

La pr√©paration du fichier de donn√©e m√©t√©o nous avait permis de r√©duire le nombre de colonnes mais celle-ci <a href="IIB1">restaient nombreuses</a>.
L'exploration viseulle de notre table m√©t√©o initiale avec la fr√©quentation cycliste ne nous permettait pas a priori de d√©gager un mod√®le simple d'analyse : de nombreux param√®tres influe en effet sur notre perception de la m√©t√©o : une temp√©rature de 12¬∞C peut-√™tre consid√©r√©e comme agr√©able pour faire du v√©lo au printemps sous le soleil mais s'il pleut et qu'il y a du vent, on pourra trouver cela froid.
Pour repr√©senter cette perception multivari√©e, Ghizalne s'est attel√©e √† la cr√©ation d'un score de M√©t√©o bas√©e sur les crit√®res:
- de temp√©rature moyenne (avec un id√©al fix√© autour de 22¬∞C);
- de quantit√© et de dur√©e des √©pisodes pluvieux
- du vent moyen.
Cette premi√®re approche nous a permis d'√©tablir un premier bar√™me de score m√©t√©o journalier, notant la cyclabilit√© des conditions m√©t√©orologiques sur 100, avec 40% de la note bas√©e sur la temp√©rature, 40% sur la pluviom√©trie et 20% sur le vent. Nous avons pu mettre en √©vidence une corr√©lation positive entre un score √©l√©v√© de m√©t√©o et la fr√©quentation des cyclistes mais il restait quelques points extr√™mes qui n'√©taient pas pris en compte.

En discutant de nos exp√©riences de cyclistes, nous avons d√©cid√© d'affiner ce premier mod√®le en compl√©tant le calcul du score avec la prise en compte :
* pour la temp√©rature :
  - d'une p√©nalit√© de grand froid bas√©e sur la temp√©rature minimale enregistr√©e
  - d'une p√©nalit√© de forte chaleur (risque de d√©shydratation ou de coup de chaleur du cycliste) bas√©e sur la temp√©rature maximale;
  - et d'une p√©nalit√© de forte amplitude thermique (perte de confort du cycliste pendulaire qui doit s'√©quiper pour le froid matinal et la chaleur de fin de journ√©e et faute de pouvoir se changer, renonce √† prendre son v√©lo);
* pour le vent avec la prise en compte du vent moyen sur 15 points et la r√©sevation de 5 points pour prendre en compte la force des rafales.

Enfin, afin de rendre ces calculs de scores intem√©diaires, nous avons √©tabi un bar√™me de classement en cat√©gorie de chacune des notes et cr√©√© des colonne de tri de ces cat√©gories (non visible de l'utilisateur de Power BI) pour que nos visuels soient coh√©rents.
Les diff√©rentes transformations √©voqu√©es peuvent √™tre consult√©es en <a href="#ann7">Annexe 7</a>.

#### II.D. Pr√©processing dans Power BI <a id="IID"></a>

##### II.D.1. Cr√©ation des tables de date <a id="IID1"></a>

La cr√©ation d'une table de date √©tait indispensable pour l'analyse temporelle de notre jeu de donn√©es.

N√©anmoins, elle n'√©tait suffisante pour pouvoir analyser la r√©partition horaire des comptages. Nous avons donc cr√©√© 2 tables de dates

Si les visuels de cr√©ation des indicateurs de fr√©quentation n√©cessitait simplement la cr√©ation des mesures appropri√©es.
Il √©tait n√©anmoins n√©cessaire de faire attention au fait que notre jeu √©tant restreint en terme de date, certaines dates de notre table de calendrier n'avaient pas de comptage : le calendrier va du 1er janvier 2024 au 31 d√©cembre 2025 mais nous n'avons des donn√©es que sur la p√©riode du 1er septembre 2024 au 30 septembre 2025. Il convenait donc d'√™tre prudent dans le calcul de nos mesures, notamment de fr√©quentation.

##### II.D.2. Mod√©lisation en √©toile <a id="IID2"></a>

Les tables pr√©par√©es ont fait l'objet de la mod√©lisation en √©toile ci-dessous :

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/etoile.png" alt="Mod√®le de donn√©e en √©toile" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 17 ‚Äî Mod√®le de donn√©e en √©toile
    </figcaption>
  </figure>
</div>

Il peut √™tre utile de mentionner la pr√©sence d'une relation One to One entre la table de Date et la table de m√©t√©o.
Bien qu'il ne soit normalement pas recommand√© d'avoir une telle relation dans le mod√®le, celle-ci se justifie par l'origine diff√©rente des tables, la table Calendrier √©tant une table calcul√©e, contrairement √† la table m√©t√©o.<br>

Nous aurions pu r√©soudre ce probl√®me en transformant dans PowerQuery notre table de m√©t√©o en table de calendrier, en s'assurant de l'absence de date manquante (ce qui √©tait bien le cas) mais nous y avons pens√© trop tard (apr√®s avoir d√©j√† cr√©√© la table en DAX) et nous avons pr√©f√©r√© conserv√© la simplicit√© d'une table de Calendrier explicite distincte d'une table stockant non seulement des dimensions temporelles mais √©galement des faits m√©t√©orologiques.

##### II.D.3. Cr√©ation des hi√©rarchies <a id="IID"></a>

Nous avons cr√©√© 2 types de hi√©rarchies dans notre mod√®le s√©mantique :

* d'une part des hi√©rarchies temporelles :
  - avec une hi√©rarchie "analytique" pour prendre en compte une ann√©e 2024-2025 d√©marrant en septembre
  - avec une hi√©rarchie "ann√©e civile" pour prendre en compte la recherche √©ventuelle d'un indicateur correspondant par exemple au d√©but de l'ann√©e 2025, la Mairie de Paris faisant habituellement ses √©tudes sur une plage de donn√©e annuelle<a href="bib201" class="ref">[2a]</a>.

* d'autre part une hi√©rarchie g√©ographique simplement bas√©e sur le rattachement d'un ou plusieurs compteurs √† un m√™me identifiant de site de comptage.
  Nous n'avons volontairement pas r√©alis√© d'analyse bas√©e sur l'adresse (on distingue ainsi les sites de comptage du 27 bd Diderot et du 28 bd Diderot) ou sur l'arrondissement.<br>
  Cette derni√®re distinction pourrait cependant avoir un int√©r√™t si la Mairie de Paris souhaitait √©tablir par exemple une liste de priorit√© par arrondissement ou si le rapport √©tait √† destination de plusieurs d√©cideurs, chacun dans leurs mairies d'arrondissement. Mais les points de comptages √©tant situ√©s sur des axes structurants des d√©placements parisiens et non sur le r√©seau secondaire, la comp√©tence est plut√¥t centralis√©e et nous ne voyions pas l'int√©r√™t de compliquer plus l'analyse.<br><br>
  En cas de besoin, on pourrait n√©anmoins envisager la cr√©ation d'une application s√©par√©e pour l'audiance de d√©cideurs en mairie centrale de celle de l'audience en mairie d'arrondissement.

##### II.D.4. Cr√©ation des mesures de sensibilit√© √† la m√©t√©o <a id="IID4"></a>

En explorant les r√©sultats de trafic cycliste en fonction des r√©sultats de la m√©t√©o, nous nous sommes aper√ßus que tous les sites n'avaient pas le m√™me comportement :

<div style="text-align:center; margin: 20px 0;">  
  <figure style="display:inline-block; width:45%; margin:0 1%;">
    <img src="images/ensemble_meteo.png" alt="Effet des conditions m√©t√©o sur le trafic cycliste √† Paris" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 18 ‚Äî Effet des conditions m√©t√©o sur le trafic cycliste √† Paris
    </figcaption>
  </figure>
  <figure style="display:inline-block; width:45%; margin:0 1%;">
    <img src="images/Diderot_meteo.png" alt="emplacement commentaires FUB 2025" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 19 ‚Äî Effet des conditions m√©t√©o sur le trafic cycliste au 28 bd Diderot
    </figcaption>
  </figure>
</div>

Il nous a donc sembl√© utile d'√©tudier la sensibilit√© des diff√©rents sites aux conditions m√©t√©orologiques par rapport √† la moyenne des sites afin de pouvoir identifier des sites qui y seraient plus ou moins sensibles, ce qui nous renseignerait sur d'√©ventuels actions √† apporter sur les am√©nagements.

Pour cela, nous avons pour chacun de nos 3 composantes du score m√©t√©o (temp√©rature, vent et pluviom√©trie), s√©par√© notre jeu de donn√©es en 2 :
* d'une part notre jeu de r√©f√©rence, correspondant aux donn√©es pour lesquelles la m√©t√©o √©tait consid√©r√© comme excellente pour le param√®tre √©tudi√©
* d'autre part le reste des donn√©es, correspondant aux donn√©es pour lesquelles la m√©t√©o √©tait moins cl√©mente voire carr√©ment d√©grad√©e.
Nous avons ainsi pu calculer la diff√©rence de fr√©quentation observ√©e sur la p√©riode "temps moins agr√©able" par rapport √† la p√©riode "conditions excellentes" et cet √©cart (directement li√© √† la variance de nos donn√©es), nous a permis de mesurer l'effet de r√©f√©rence du param√®tre.

Dans un second temps, nous avons cr√©√© ue mesure d√©finissant pour chaque compteur l'effet observ√© c'est √† dire l'√©cart de fr√©quentation entre jours excellents et jours moins agr√©ables.

La diff√©rence entre cet effet observ√© et l'effet de r√©f√©rence a consistu√© notre indicateur de sensibilit√© √† la m√©t√©o, dont vous pouvez trouver un exemple en <a href="#ann8">Annexe 8</a> et qui nous a permis d'√©tablir un classement des sites plus ou moins sensibles √† la m√©t√©o.

##### II.D.5. Cr√©ation des mesures de saturation des am√©nagements <a id="IID5"></a>

Constatant des fr√©quentations exceptionnellement √©lev√©e pour certains compteurs, nous avons d√©cid√© de compl√©ter notre rapport d'un indicateur de saturation des am√©nagements cyclables, afin de pouvoir alerter les am√©nageurs lorsque la fr√©quentation d'un site devient si √©lev√©e que cela peut g√©n√©rer des probl√®mes, alors m√™mes que l'objectif du Plan V√©lo 2021-2026 est bel et bien la croissance de la part modale du v√©lo.


<a href="#ann9">Annexe 9</a>

## III. Visualisations dans Power BI <a id="III"></a>

### III.A. Th√®me et organisations visuelles des pages

Nous avons choisi de pr√©parer notre rapport "comme si nous allions aller jusqu'√† l'√©tape de publication".
Dans ces conditions, nous avons donc pr√©vu un cadre classique avec un bandeau lat√©ral pour la navigation entre les pages de rapport et un bandeau horizontal pour le titre.

Nous avons s√©lectionn√© un th√®me neutre en terme de couleur pour ne pas influencer nos utilisateurs dans leur perception des r√©sultats affich√©s et avons choisi d'appliquer un jeu de couleur accessible √† notre rapport.

L'objectif du rapport est d'aider l'utilisateur du rapport √† prendre des d√©cisions n√©cessitant :
* d'identifier des sites prioritaires,
* d'identifier pour ces sites les axes d'am√©liorations possibles.

Nous avons donc d√©cid√© de cr√©er 2 pages principales √† notre rapport : une page macro permettant de visualiser l'ensemble des sites de comptage et une page de focus √† la maille du site de comptage.
Nous compl√©terons √©ventuellement de page d√©taillant des analyses de sensibilit√© m√©t√©o mais souhaitons conserver la simplicit√© d'un nombre r√©duit de page et de visualisation car notre public de d√©cideur a rarement du temps √† consacrer √† la navigation au sein d'un rapport.

### III.B. La page d'accueil du rapport

Nous avons donc d√©cid√© d'organiser notre rapport avec une premi√®re page pr√©sentant une vision macro de l'ensemble de nos donn√©es : indicateurs de fr√©quentation, de saturation, localisation des compteurs, sensibilit√© √† la m√©t√©o.<br>
Deux crit√®res de filtre sont retenus : 
* les sites de comptage (avec la possibilit√© d'en s√©lectionner plusieurs, par exemple le 27 et le 28 bd Diderot ou tous les ponts) 
* et la p√©riode calendaire, avec une premier niveau de s√©lection fix√© sur la saison m√©t√©orologique, ce qui nous a sembl√© le plus simple pour comparer facilement les moyennes √©t√© vs hiver par exemple.<br><br>

Si les visuels de cr√©ation des indicateurs de fr√©quentation n√©cessitaient simplement la cr√©ation des mesures appropri√©es (moyenne, maximum). Il √©tait n√©anmoins n√©cessaire de faire attention au fait que notre jeu √©tant restreint en terme de date, certaines dates de notre table de calendrier n'avaient pas de comptage : le calendrier va du 1er janvier 2024 au 31 d√©cembre 2025 mais nous n'avons des donn√©es que sur la p√©riode du 1er septembre 2024 au 30 septembre 2025. Il convenait donc d'√™tre prudent dans le calcul de nos mesures, notamment de fr√©quentation.<br>

Carte de situation des compteurs

Int√©gration du visuel Python de nuage de mot
<a href="#bib101" class="ref">[6a]</a>
<a href="#ann10">Annexe 10</a>

Ceci nous fourni les √©l√©ments n√©cessaire √† la r√©alisation de notre page, organis√©e "en Z": nos indicateurs de fr√©quentation en haut √† gauche, puis ceux de saturation, √† droite une carte de Paris avec les avis des cyclistes en survol. En partie basse, une liste des sites les plus sensibles √† la m√©t√©o et √† droite la liste des sites les plus fr√©quent√©s.

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/page1.gif" alt="Page d'accueil du rapport Power Bi" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 20 ‚Äî Page d'accueil du rapport Power BI
    </figcaption>
  </figure>
</div>

### III.C. La page de Focus Site

Ayant constat√© que la Mairie de Paris suit un indicateur au seuil de 3000 cyclistes/jour<a href="bib201" class="ref">[2a]</a>, nous sommes rest√© sur un indicateur journalier pour la visualisation de la saturation au cours de l'ann√©e avec un bandeau horizontal permettant d'un simple glissement de rep√©rer les fr√©quences de d√©passement des seuils.<br>
Deux seuils ont √©t√© trac√©s sur le graphe :
* un premier seuil √† 1 500 cyclistes/jour correspond aux trafic maximum souhait√© sur une bande cyclable non prot√©g√© suivant les recommandations du Cerema <a href="bib301" class="ref">[3a]</a>.
* un second seuil √† 3 000 cyclistes/jour correspond √† un seuil habituellement tol√©rable sur des pistes cyclables de taille confortable type "haut niveau de service" telle qu'on peut les trouver dans les am√©nagements de type v√©lopolitain <a href="bib302" class="ref">[3b]</a><a href="bib303" class="ref">[3c]</a><a href="bib401" class="ref">[4a]</a>.
Il faut noter qu'en l'absence de liaison avec lun jeu de donn√©es des am√©nagements cyclables, nous n'avons pas pu d√©terminer dynamiquement quel seuil √©tait le plus adapt√© √† chaque site mais nous consid√©rons que les am√©nageurs connaissent leurs sites et sinon, un simple clic dans la carte permet d'acc√©der √† une photo sommaire de l'emplacement pour se le remettre en t√™te.

<div style="text-align:center; margin: 20px 0;">
  <figure style="display:inline-block; width:100%; margin:0 1%;">
    <img src="images/sebastopol9000.png" alt="Page Focus site rapport Power Bi" style="width:100%; display:block;">
    <figcaption style="font-size:0.66em; margin-top:6px;">
      Figure 20 ‚Äî Page Focus site du rapport Power BI
    </figcaption>
  </figure>
</div>

Mais si le cycliste parisien est relativement noctambule, nous avons vu dans nos explorations que des pics horaires sont bien visibles, tant en semaine que nous le week-end et nous compl√©terons donc nos visualisations d'un indicateur de flux maximum horaire. ainsi que d'un histogramme permettant de visualiser les pics maximums par rapport √† un seuil horaire maximal correspondant.

<div style="display: table; width: 100%;">
  <div style="display: table-cell; width: 55%; vertical-align: top; padding-right: 12px;">
  Bien que la journ√©e dure 24h, il est g√©n√©ralement admis par les am√©nageurs qu'un seuil de 1500 cyclistes/jour est √† peu pr√®s √©quivalent √† un seuil de 125 cyclistes/heure (250 cyclistes/heure pour le seuil √† 3000 cyclistes/jour) : en effet, ce qui nous int√©resse c'est d'identifier les d√©passements de seuil et non de faire des moyennes pr√©cises, hors la majeure partie du trafic cycliste a lieu sur un une douzaine d'heure par jour.
  Nous tra√ßons donc notre constantes sur ces bases.
  </div>
  <div style="display: table-cell; width: 45%; vertical-align: top;">
    <figure style="margin:0;">
        <img src="images/focus_Diderot_horaire.png" alt="Seuils de fr√©quentations horaire" style="width:100%;">
        <figcaption>
         Figure 21 ‚Äî Seuils de fr√©quentations horaire
        </figcaption>
    </figure>
   </div>
</div>

<hr class="page-break">

## IV. Analyse des donn√©es <a id="IV"></a>

<hr class="page-break">

## Conclusion

### Bilan

### Perspectives :

1. **Enrichir le jeu de donn√©es avec celui des am√©nagements cyclables.**<a id="persp1"></a>

Ceci nous aurait permis d'analyser s√©par√©ment les compteurs sur bande cyclables de ceux sur pistes cyclables par exemple ou de prendre en compte pour ces derni√®res la largeur de l'am√©nagement afin de pr√©ciser les risques de saturation.
Un tel jeu existe et est disponible [ici](https://www.openstreetmap.org/search?query=Paris&zoom=5&minlon=-34.40917968750001&minlat=38.03078569382294&maxlon=34.23339843750001&maxlat=61.897577621605016#map=13/48.85890/2.33116&layers=C) grace au travail des contributeurs d'OpenStreeMap.<br>

La Ville de Paris ne produit pas sa propre carte mais retraite cette carte collaborative en qualifiant la qualit√© de la donn√©e et en la mettant √† disposition sur son propre OpenData  [ici](https://opendata.paris.fr/explore/dataset/amenagements-cyclables/information/?disjunctive.arrondissement&disjunctive.position_amenagement&disjunctive.vitesse_maximale_autorisee&disjunctive.source&disjunctive.amenagement).<br>

Mais son traitement pour int√©gration dans le jeu de donn√©e nous aurait pris trop de temps et nous nous sommes donc content√© d'une analyse visuelle de l'am√©nagement au travers de la photo du site. En effet, le jeu est plus complexe qu'il n'y para√Æt : 

* plusieurs traces GPS peuvent √™tre superpos√©es sur une m√™me voie lorsque l'am√©nagement est bidirectionnel ou √™tre unique lorsqu'il est unidirectionnel, le nombre de cat√©gorie d'am√©nagement list√© est bien plus important que celui √† proximit√© des compteurs (du double sens cyclable √† la piste bidirectionnelle en passant par la voie verte, la v√©lorue o√π la voie partag√©e avec les bus pour n'en citer que quelques uns.)
* les am√©nagements se g√®rent comme des dimensions √† √©volution lente (une fois tous les x mois, un am√©nagement va √™tre mis √† jour pour indiquer par exemple la fin des travaux de cr√©ation d'une voie de v√©lopolitain) tandis que notre jeu de donn√©e √† une temporalit√© courte avec des donn√©es horaires.

1. **Identifier l‚Äôordre d‚Äôimportance des facteurs responsables des variations de flux :** <a id="persp2"></a>

Que ces variations soient horaires (effet de journ√©e de travail), hebdomadaires (semaine de travail vs weekend), saisonni√®res (effet des vacances d'√©t√©t ou des f√™tes de fin d'ann√©es) ou m√©t√©orogoliques, nous avons en effet pu voir que de nombreux √©l√©ments √©taient √† l'origine des variations.<br>
Si nous avions eu le temps d'aborder les cours de machine learning un peu plus t√¥t.<br>
Ainsi, nous aurions par exemple pu utiliser un arbre de r√©gression pour ajuster notre calcul de scoring m√©t√©o, qui est actuellement bas√© avant tout sur une approche "mon v√©cu de cycliste" que sur une d√©marche statistique.<br>
Nous aurions par ailleurs pu tenter d'identifier l'ordre d'importance de ces facteurs pour affiner l'identification des sites n√©cessitant des modifications d'am√©nagements.

1. **Rendre dynamique le rapport en le raccordant directement via API.**<a id="persp3"></a>

Ceci nous aurait permis d'√©largir la p√©riode de donn√©e utilis√©e plut√¥t que de se restreindre √† 13 mois (donc d'avoir plusieurs √©t√©s, plusieurs vacances d'hiver...).<br>

Le jeu √©tant actualis√© quotidiennement avec de nombreux compteurs install√©s depuis plus de 6 ans, nous aurions ainsi pu √©tudier des tendances et les donn√©es suppl√©mentaires nous auraient permis de commencer √† faires des pr√©dictions de trafic pour affiner l'identification des sites :

  * pour lesquels un am√©nagement permettrait d'√©viter une future saturation,
  * ou pour lesquels un am√©nagement favoriserait le d√©veloppement de la part modale cycliste.

4. **Enrichir le jeu de donn√©es avec les jeux de donn√©es sur l'accidentologie.**<a id="persp4"></a>

Le jeu dit "fichier BAAC" (Base de donn√©es Annuelles des Accidents Corporels de la circulation routi√®re de l'Observatoire National Interminist√©riel de la S√©curit√© Routiers (ONISR) est librement accessible [ici](https://www.data.gouv.fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2024), inclue une localisation des accidents et permetttrait d'am√©liorer l'identification et la quantification les zones dangereuses afin de prioriser les travaux sur ces zones.

### Les difficult√©s qu'il a fallu relever

1. **Les contraintes du travail d'√©quipe en mode projet :** <a id="defi1"></a>

Nous avons d√©couvert GitHub tous ensemble en collaborant sur un repository priv√© h√©berg√© sur mon GitHub personnel. L'id√©e √©tait d'avoir chacun sa branche pour travailler et de consolider nos avanc√©es dans la branche *main*.<br>
Mais les d√©buts ont √©t√© compliqu√© et j'ai du √† plusieurs reprises utiliser les fonctions de revert ou reset suite √† des *merge* "√† l'envers" de certains de mes coll√®gues‚Ä¶ l‚Äôabsence de formation √† l'utilisation d'un outil de versionning dans le cadre de la formation a √©t√© un r√©el manque m√™me si nous avons pu nous appuyer sur ls modules Microsoft Learn.<br>

D'autre part, les contraintes de travail sur PowerBI SANS acc√®s √† Power BI ont √©t√© assez contraignantes car une seule personne pouvait travailler √† la fois sur le rapport, faute de pouvoir publier un mod√®le s√©mantique commun et d'avancer s√©par√©mment sur diff√©rentes visualisation. Il a fallu jouer sur les calendriers des acc√®s et les contraintes de chacun ce qui n'a pas toujours √©t√© simple.<br>
Si nous avions eu le temps de nous former aux nouvelles fonctions Power BI, nous aurion spu essayre d'utiliser le format d'enregistrement pbip et les fichiers TMDL pour travailler en parral√®le sur diff√©rents √©l√©ments de notre rapport (par exemple une personne travaillant sur les transformations power query de score m√©t√©o pendant qu'un autre travaillait sur les renommage de compteurs) en parall√®me en utilisant Git pour tracer les modifications de chacun, ces fonctions semblant vraiment tr√®s int√©ressantes pour le travail collaboratif et la gestion de version.<br><br>

2. **La compr√©hension des notions d‚Äôenvironnements python et de gestion de version des librairies Python :** <a id="defi2"></a>

Nous avons √©t√© confront√© √† des erreurs li√©s √† ce type de probl√®me car nous avions tous les 3 des versions diff√©rentes de Python (3.13.5 pour moi et Ghizlane sur oc, 3.14 pour Mohammed sur mac).<br>
J'ai √©galement eu des conflits de versions de librairies Python et il aurait √©t√© judicieux de mettre en place un environnement partageable pour stabiliser notre travail, d'autant que sans Power BI Service, chaque utilisateur doit pour l'instant d√©clarer son propre environnement python pour faire fonctionner le rapport.<br>
Un module de formation sur les bonnes pratiques d‚Äôutilisation d‚Äôun EDI comme VS Code aurait √©t√© appr√©ci√©, ainsi que sur les modalit√©s de cr√©ation d'un environnement Python et son partage.<br><br>

3. **L‚Äôanalyse de texte en fran√ßais :** <a id="defi3"></a>

Il a fallu rechercher une biblioth√®que python adapt√©e (celle vu en cours, wordnet √©tant plut√¥t anglophone) et qui puisse prendre en compte les formes complexes du fran√ßais.<br>
La transformation du script test√© sur l‚Äôensemble du jeu en un script int√©grable dans Power BI et fonctionnant avec des clusters d‚Äôavis de taille nettement plus r√©duite pour chaque compteur a ensuite n√©cessit√© des ajustements  pour ne pas avoir d‚Äôerreur lorsque le cluster √©tait petit.<br>
D'autre part, le rendu de l'affichage du nuage de mot dans Power BI √©tait l√©g√®rement diff√©rent application arbitraire de marge en haut et en base) que celui obtenu dans Python et j'ai donc du adapter ces param√®tres.<br>
Enfin (et surtout), pour des raisons de performance (temps de chargement qui √©tait trop long), j'ai √©galement du mettre directement dans le script python la d√©finition de la totalit√© du dictionnaire de mots vides √† utiliser au lieu de charger dynamiquement les mots vides "classiques" et de me contenter d'y ajouter les mots sp√©cifiques √† mon contexte.<br><br>

<hr class="page-break">

## Bibliographie

### 1. Plans v√©lo et qualit√© de l'air

<a id="bib101">[1a]-</a>[Mesures pour modifier le trafic routier en ville et qualit√© de l'air ext√©rieur - Edition Ademe - 2021](https://librairie.ademe.fr/urbanisme-territoires-et-sols/4927-mesures-pour-modifier-le-trafic-routier-en-ville-et-qualite-de-l-air-exterieur.html)

### 2. D√©placements √† Paris

<a id="bib201">[2a]-</a>[Bilan des d√©placements √† Paris en 2024 - page web Ville de Paris - oct 2025](https://www.paris.fr/pages/le-bilan-des-deplacement-a-paris-en-2024-31371)

<a id="bib202">[2b]-</a>[Les d√©placements en v√©lo √† Paris en 2024 - Edition Ville de Paris - 2025](https://cdn.paris.fr/paris/2025/06/02/paris_ra2024-deplacements-en-velo-8-pages-26-05-copie-3dZs.pdf)

### 3. Qualit√© des am√©nagements cyclables (Guides officiels )

<a id="bib301">[3a]-</a>[Annexe 3 : Note de recommendations techniques du CEREMA](https://www.ecologie.gouv.fr/sites/default/files/documents/Annexe%203%20%20Recommandations%20techniques%20du%20CEREMA.pdf)

<a id="bib302">[3b]-</a>[8 recommandation pou r√©ussir votre piste cyclable - Actualit√©s du Cerema - 24/02/2021](https://www.cerema.fr/fr/actualites/8-recommandations-reussir-votre-piste-cyclable) 

<a id="bib303">[3c]-</a>[Guide des am√©nagements cyclables - Direction de la Voirie des tdes D√©placements de la Ville de Paris - 16/06/2023](https://cdn.paris.fr/paris/2024/09/30/guide-amenagements-cyclables-partie-1-generalites-hors-dsc-juin-2024-light-CFZy.pdf)

### 4. Paris en Selle <img src=".\images\logo_pes.png" style="height:100px">

Qualit√© des am√©nagements cyclables (nombreuses photos et exemples) pour la compr√©hension des sites de comptage :
<a id="bib401">[4a]-</a>[Guide des am√©nagements cyclables - Edition : Paris en Selle - mise √† jour de 20121](https://parisenselle.fr/telecharger-guide-amenagements-cyclables/)

<a id="bib402">[4b]-</a>[Plateforme d√©di√©e aux compteurs v√©lo](https://parisenselle.fr/2020/10/06/une-plateforme-pour-recenser-les-compteurs-velo/#:~:text=Nous%20sommes%20heureux%20de%20vous%20pr%C3%A9senter%20https%3A%2F%2Fcompteurs.parisenselle.fr%2C%20qui,grand%20merci%20%C3%A0%20Tristram%20pour%20ce%20gros%20boulot.)


### 5. Compr√©hension des fonctionnement des capteurs et des m√©thodes de suivi du trafic

<a id="bib501">[5a]-</a>[Donn√©es de mobilit√© pour la mod√©lisation des d√©placements - fiche n¬∞9 : donn√©es issues des capteurs routiers - Edition : Cerema - 2025](https://doc.cerema.fr/Default/doc/SYRACUSE/605087/donnees-de-mobilite-pour-la-modelisation-des-deplacements-fiche-n-9-donnees-issues-des-capteurs-rout)

<a id="bib502">[5b]-</a>[Technologies de comptage propos√©es pour les cyclistes par eco-compteur - page web - 2025]](https://www.eco-compteur.com/solutions/produits/)

<a id="bib503">[5c]-</a>[Etude de simulation dynamique de trafic : guide de r√©alisation - Edition : Cerema - 2015](https://doc.cerema.fr/Default/doc/SYRACUSE/14114/etudes-de-simulation-dynamique-de-trafic-guide-de-realisation) => perspectives (analyse dynamique des flux)

### 6. Documentation technique compl√©mentaire

<a id="bib601">[6a]-</a>[Cr√©er un script Python pour Power Bi - page Web Microsoft Learn - oct 2025](https://learn.microsoft.com/fr-fr/power-bi/connect-data/desktop-python-scripts)

<hr class="page-break">

## Annexes et extrait de code

### <a id="ann1">Annexe 1</a> : üóÇÔ∏è Structure du projet et du fichier zip

_Certains fichiers pr√©sents ne sont pas d√©crits : il s'agit soit de fichier qui ont √©t√© √©cart√©s du traitement (par exemple les fichiers compl√©mentaires du barom√®tre FUB, soit de fichiers de travail temporaires.)_

```text
trafic_cycliste_paris/
‚îÇ
‚îú‚îÄ‚îÄ data                                    ‚Üí donn√©es brutes et nettoy√©es
|    |‚îÄ‚îÄ raw                                ‚Üí donn√©es brutes
|    |    |‚îÄ‚îÄmeteo
|    |    |    |‚îÄ‚îÄQ_75_latest-2024-2025_RR-T-Vent.csv
|    |    |    ‚îî‚îÄ‚îÄQ_75_latest-2024-2025_RR-T-Vent.csv.gz
|    |    |‚îÄ‚îÄbarometre2025fub               ‚Üí donn√©es du barom√®tre FUB pour la ville de Paris
|    |    |    |‚îÄ‚îÄpoints-rouges-75056.geojson
|    |    |    |‚îÄ‚îÄpoints-verts-75056.geojson
|    |    |    ‚îî‚îÄ‚îÄstationnements-75056.geojson
|    |    |‚îÄ‚îÄbarometre2025fub-dept75        ‚Üí donn√©es du barom√®tre FUB pour le d√©partement Paris
|    |    |    |‚îÄ‚îÄclusters-rouges-75.geojson
|    |    |    |‚îÄ‚îÄclusters-stationnements-75.geojson
|    |    |    ‚îî‚îÄ‚îÄclusters-verts-75.geojson
|    |    |‚îÄ‚îÄbarometre2025fub-dept75        ‚Üí donn√©es sociologiques du barom√®tre FUB 2025
|    |    |‚îÄ‚îÄcomptage-velo-donnees-compteurs.csv        // jeu de donn√©e principal
|    |    |‚îÄ‚îÄcomptage-velo-donnees-compteurs.geojson    // m√™me jeu, simple diff√©rence de format
|    |    ‚îî‚îÄ‚îÄcomptage-velo-donnees-compteurs.parquet    // m√™me jeu, simple diff√©rence de format
|    ‚îî‚îÄ‚îÄ processed  ‚Üí donn√©es retravaill√©es ‚Üí donn√©es issues du pr√©-processing
|         |                             -------source pour Power BI-------
|         |‚îÄ‚îÄcomptage-velo-donnees-compteurs-allege.csv   // ignore pour GitHub car trop gros
|         |‚îÄ‚îÄcompteurs_velo.csv
|         |‚îÄ‚îÄmeteo.csv
|         |‚îÄ‚îÄcommentaires_enrichis_sites.csv
|         |                             -------fichiers de traitement interm√©diaire-------
|         |‚îÄ‚îÄcommentaires.csv                           
|         |‚îÄ‚îÄpoints-rouges-75056.csv                    
|         |‚îÄ‚îÄpoints-verts-75056.csv                     
|         ‚îî‚îÄ‚îÄstationnements-75056.csv 
|
‚îú‚îÄ‚îÄ models                                  ‚Üí stockage √©ventuels des mod√©lisations et calcul pr√©dictif (non utilis√©)
‚îú‚îÄ‚îÄ notebooks                               ‚Üí jupyter notebooks utilis√©s pour l'exploration et l'analyse
|    |‚îÄ‚îÄ Rapport_de_d√©couverte.ipynb                             //premier rapport
|    |‚îÄ‚îÄ Rapport_d_exploration.ipynb                             //consolidation et compl√©ment des rapports d'exploration
|    |‚îÄ‚îÄ m√©t√©o.ipynb                                             // premi√®re exploration du jeu m√©t√©o
|    |‚îÄ‚îÄ barom√®tre2025.ipynb                                     // premi√®re exploration du jeu de commentaire et nuages de mots
|    |‚îÄ‚îÄ jointure_spacialeV1.ipynb                               // premi√®re version jointure clusters commentaire-site
|    |‚îÄ‚îÄ rapprochement_commentaires_et_sites_comptage.ipynb      // premi√®re int√©gration jointure dans table commentaire-site  
|    |‚îÄ‚îÄ jointure_spatiale.ipynb                                 // consolidation jointure commentaire-site et calcul rayon           
|    ‚îî‚îÄ‚îÄ images                             ‚Üí stockage des images d'illustration (y compris cartes)                             
|
‚îú‚îÄ‚îÄ reports         ‚Üí stockage des projets de datavisualisation (PowerBI)
|    ‚îî‚îÄ‚îÄ Rapport_trafic_cycliste.pbix
|
‚îú‚îÄ‚îÄ references      ‚Üí metadatas de fichier sources et documents d'informations diverses
|    |‚îÄ‚îÄ metadatas-donnees-brutes.txt
|    |‚îÄ‚îÄ colonnes_meteo.csv                                       //extrait notice en ligne du jeu m√©t√©o
|    |‚îÄ‚îÄ metadatas-donnees-meteo-brutes.txt
|    |‚îÄ‚îÄ metadatas-donnees-comptage.txt
|    |‚îÄ‚îÄ metadatas-donnees-compteur.txt
|    |‚îÄ‚îÄ metadatas-donnees-commentaires.txt
|    ‚îî‚îÄ‚îÄ metadatas-donnees-meteo.txt           
‚îú‚îÄ‚îÄ utilitaires     ‚Üí module python de stockage des scripts python utilis√©es dans les notebooks notamment
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```
<hr class="page-break">

### <a id="ann2">Annexes 2</a> : Struture des jeux de donn√©ees initiaux

Les informations ci-dessous ont √©t√© extraites des jeux par l'application de la fonction ci-dessous :

```python
def info_colonnes(df):
    infos = []  # liste qui va contenir les infos de chaque colonne
    
    for col in df.columns:
        # R√©cup√©rer le type de la colonne
        dtype = df[col].dtype
        nb_unique=df[col].nunique()
        nb_manquant=df[col].isnull().sum()
        pct_manquant=f"{df[col].isnull().mean() * 100:.2f}%"
        nb_doublon=df[col].duplicated().sum()
        nb_identifiant_non_unique=df[col].duplicated(keep=False).sum()
        ex_unique=f" {df[col].unique()[:5]}"  # Affiche les 5 premi√®res valeurs uniques  
                    
        infos.append(f"</p><p>Nom de la colonne: {col}\n Type : {str(dtype)}\nNombre de valeurs uniques : {str(nb_unique)}\nNombre de valeurs manquantes : {str(nb_manquant)}\nPourcentage de valeurs manquantes : {str(pct_manquant)}\nNb √©lements utilis√©s plusieurs fois : {str(nb_doublon)}\nsoit nb lignes avec un √©l√©ment non unique : {str(nb_identifiant_non_unique)}\nExemples de valeurs uniques : {str(ex_unique)}\n")
        
    # Retourner une seule cha√Æne compos√©e des descriptions de chaque colonne
    # pour pouvoir l'√©crire facilement dans un fichier de m√©tadonn√©es.
    return "\n\n".join(infos)

# on va venir enregistrer la description des donn√©es brutes dans un fichier txt de m√©tadonn√©es

file_metadonnees=chemin_user+"references/metadatas-donnees-brutes.txt"
   
with open(file_metadonnees,"w") as f:
    f.write("Structure du jeu de donn√©es initial brut :\n")

with open(file_metadonnees,"a") as f:
    content=str(info_colonnes(df))
    f.write(content)
    f.close()

```

<hr class="page-break">

#### <a id="ann2a">Annexe 2a</a> : Structure du jeu de donn√©es initial brut

<div class="two-columns">
<p>Nom de la colonne: Identifiant du compteur<br>
 Type : object<br>
Nombre de valeurs uniques : 98<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885145<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['100003098-101003098' '100006300-101006300' '100007049-102007049'
 '100007049-101007049' '100036718-104036718']<br>
</p>
<p>Nom de la colonne: Nom du compteur<br>
 Type : object<br>
Nombre de valeurs uniques : 109<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885135<br>
soit nb lignes avec un √©l√©ment non unique : 885243<br>
Exemples de valeurs uniques :  ['106 avenue Denfert Rochereau NE-SO' '135 avenue Daumesnil SE-NO'
 '28 boulevard Diderot E-O' '28 boulevard Diderot O-E'
 '39 quai FranÔøΩois Mauriac NO-SE']<br>
</p>
<p>Nom de la colonne: Identifiant du site de comptage<br>
 Type : float64<br>
Nombre de valeurs uniques : 69<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885174<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  [1.00003098e+08 1.00006300e+08 1.00007049e+08 1.00036718e+08
 1.00036719e+08]<br>
</p>
<p>Nom de la colonne: Nom du site de comptage<br>
 Type : object<br>
Nombre de valeurs uniques : 66<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885177<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['106 avenue Denfert Rochereau' '135 avenue Daumesnil'
 '28 boulevard Diderot' '39 quai Fran√ßois Mauriac'
 "18 quai de l'H√¥tel de Ville"]<br>
</p>
<p>Nom de la colonne: Comptage horaire<br>
 Type : int64<br>
Nombre de valeurs uniques : 1384<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 883860<br>
soit nb lignes avec un √©l√©ment non unique : 884963<br>
Exemples de valeurs uniques :  [  0   6  34 165 195]<br>
</p>
<p>Nom de la colonne: Date et heure de comptage<br>
 Type : object<br>
Nombre de valeurs uniques : 9474<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 875770<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['2024-09-01T06:00:00+02:00' '2024-09-01T08:00:00+02:00'
 '2024-09-01T05:00:00+02:00' '2024-09-01T15:00:00+02:00'
 '2024-09-01T09:00:00+02:00']<br>
</p>
<p>Nom de la colonne: Date d'installation du site de comptage<br>
 Type : object<br>
Nombre de valeurs uniques : 39<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885204<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['2012-02-22' '2013-01-19' '2013-01-18' '2017-07-12' '2013-01-17']<br>
</p>
<p>Nom de la colonne: Lien vers photo du site de comptage<br>
 Type : object<br>
Nombre de valeurs uniques : 68<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885175<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['https://filer.eco-counter-tools.com/file/09/73f38aaf49fa85ee19ee67277787a24af6b31b497e0fbf06bf2970b4449a0409/Y2H16029278_20200818121425.jpg'
 'https://filer.eco-counter-tools.com/file/0f/72fcbc343c96fd864d33966e6ca86ed6454fe348c579812ed9c674cf39d1310f/X2H18086316_20240618155704.jpg'
 'https://filer.eco-counter-tools.com/file/4a/2e6127480864e11e9bd152969a114c01c26ea9434bdd7813bc618f511a21b04a/Y2H21015011_20220407110543.jpg'
 'https://filer.eco-counter-tools.com/file/16/35f6b42be906d8dc8ac074b0bfc2683cec4aa3aa4cff6e964ff4a73697ed8816/Y2H21015068_20240618150003.jpg'
 'https://filer.eco-counter-tools.com/file/31/7a51f8668baa67fe9fbc33f577ca62cffa13fab69148810676d42c23d007dc31/15374519009810.png']<br>
</p>
<p>Nom de la colonne: Coordonn√©es g√©ographiques<br>
 Type : object<br>
Nombre de valeurs uniques : 69<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885174<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['48.83507, 2.33305' '48.843435, 2.383378' '48.84613, 2.37559'
 '48.83436, 2.377' '48.85372, 2.35702']<br>
</p>
<p>Nom de la colonne: Identifiant technique compteur<br>
 Type : object<br>
Nombre de valeurs uniques : 68<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885175<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['Y2H20114504' 'X2H18086316' 'Y2H21015011' 'Y2H21015068' 'Y2H21015012']<br>
</p>
<p>Nom de la colonne: ID Photos<br>
 Type : object<br>
Nombre de valeurs uniques : 68<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885175<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['https://filer.eco-counter-tools.com/file/09/73f38aaf49fa85ee19ee67277787a24af6b31b497e0fbf06bf2970b4449a0409/Y2H16029278_20200818121425.jpg/https://filer.eco-counter-tools.com/file/1e/766b4ae7bba5ee2e4e87b5ed3990964e393647406bf7169c7b948612c014911e/15977456895210.jpg/https://filer.eco-counter-tools.com/file/96/cf95805b6c2fba4a722174ed6d93acf65a2503bbf41ad417508b20e10ebb6496/Y2H16029278_20220803102622.jpg/https://filer.eco-counter-tools.com/file/9c/21fe20ab12a64990b0db744ec805262d6ac64fca0800e5dc887432307ffab29c/Y2H21110997_20231031090022.jpg/https://filer.eco-counter-tools.com/file/ad/53597f9018bb78ed4018cccaf73e0d792319673f5297297e72b624b221788cad/13305145395420.jpg/https://filer.eco-counter-tools.com/file/ae/9bc3209eb84338645b0dbe0b578336e0e5e9c0103bb2119f6a4694ae5defa0ae/Y2H20114504_20240611133259.jpg/https://filer.eco-counter-tools.com/file/bd/ae1f16033631d0af335022b99f8d2de3e823a970d8b4ae1cc349b2339a6bd2bd/Y2H16029278_20210810113212.jpg'
 'https://filer.eco-counter-tools.com/file/0f/72fcbc343c96fd864d33966e6ca86ed6454fe348c579812ed9c674cf39d1310f/X2H18086316_20240618155704.jpg/https://filer.eco-counter-tools.com/file/33/72900abae7cbd8648f613c39f98f2766804530fc2fd9004fcca1ac282a9b5c33/X2H18086316_20220803114717.jpg/https://filer.eco-counter-tools.com/file/4c/44ca3caef446f2d0daf95d1d603651d16f794169bfb14df76d2afc8daac93b4c/X2H18086316_20211004180732.jpg/https://filer.eco-counter-tools.com/file/97/3f31a803a3d2e6dc1b985b032528ea836d3e53685058af9f542c006a7de4a197/15765762690330.jpg/https://filer.eco-counter-tools.com/file/cb/ea232c18c5891153f2c0b47062b73ecc1310e9c41a33239f7f1a6a5fcf2210cb/X2H18086316_20250729134753.jpg/https://filer.eco-counter-tools.com/file/e1/6ef39ee97d7f723c14b8fe9ec91840266b3f3add70e0a817bafd66adc553c9e1/15809064565060.jpg'
 'https://filer.eco-counter-tools.com/file/4a/2e6127480864e11e9bd152969a114c01c26ea9434bdd7813bc618f511a21b04a/Y2H21015011_20220407110543.jpg/https://filer.eco-counter-tools.com/file/6b/84e46df62589a66a0827954c6c07947e87f1e1d5c80724efc19efaf54a67386b/Y2H21015011_20250729122942.jpg/https://filer.eco-counter-tools.com/file/81/7d5f7058df9d97404fb0067e49039a2a022ea3f5a732b5e54b7d2ed90afab981/Y2H21015011_20240618154402.jpg/https://filer.eco-counter-tools.com/file/9b/531a0daddb4be5433a86cb09dc36f92b25c7bd4ea5c93c7c3146181d9625539b/13585075886520.jpg/https://filer.eco-counter-tools.com/file/d0/5539296cbf2bbb9fb37428bdb5bd6fe499ea5843de9de9605700c783eaa879d0/Y2H21015011_20220407110305.jpg/https://filer.eco-counter-tools.com/file/f7/4f2f37a5b343c214e4cc32c80e8de78de6afb907af12505592b2bd2f190671f7/Y2H21015011_20220725182819.jpg'
 'https://filer.eco-counter-tools.com/file/16/35f6b42be906d8dc8ac074b0bfc2683cec4aa3aa4cff6e964ff4a73697ed8816/Y2H21015068_20240618150003.jpg/https://filer.eco-counter-tools.com/file/1b/6c9013a542a3c751f94c8b9a00db0ad3485054953a37aeddf45830482d5d311b/Y2H17021629_20200818165643.jpg/https://filer.eco-counter-tools.com/file/85/6f1a65ada98e5b9c30af21c28ced81ae2d1a3a91d27f7a5ec23a04f8e64dd185/15374559754710.png/https://filer.eco-counter-tools.com/file/89/a417e0e7a5a6a0be002e6b9f7f43b4db5eb3f1c15aa348294378f2b8d6cfa089/Y2H21015068_20220407102319.jpg/https://filer.eco-counter-tools.com/file/92/8dd0832756788947862701438d96ba9ac1f7524794109c2db14efa91a3e5bc92/Y2H21015068_20220803125012.jpg/https://filer.eco-counter-tools.com/file/9e/f997ab4793874f0832ae24c89ef2cafc87a78e90336527f7e9be38d0f4fec39e/15977626284870.jpg/https://filer.eco-counter-tools.com/file/a3/eb19fabc6ac19ee165b9a3d367b75c23705c0bc2ef3c0b7b4950e921840633a3/15765770808100.jpg/https://filer.eco-counter-tools.com/file/c3/3cc5746fc201948a4f89469db101780cf29dcc2c29e350f53351732871bfa5c3/Y2H17021629_20210810135800.jpg/https://filer.eco-counter-tools.com/file/d4/e8110bccec80e42806d28ea2f102e3cf93875f3e8add5dfa4ea0672af45ee3d4/14997911465211.jpg/https://filer.eco-counter-tools.com/file/d9/e055c4b719c875d6a250c8caf4ed5962c847d9d3b04251f053e86b5d088c2ad9/15767555313320.jpg/https://filer.eco-counter-tools.com/file/f2/1f6decacff618a4b568543f90909d8f562fd951737e6b8f53dbe567d64f87cf2/Y2H21015068_20250729150243.jpg'
 'https://filer.eco-counter-tools.com/file/31/7a51f8668baa67fe9fbc33f577ca62cffa13fab69148810676d42c23d007dc31/15374519009810.png/https://filer.eco-counter-tools.com/file/54/8946a312899f621b1e2c7007e9f490f297cd915b9dfee93b4c96c557d5179c54/Y2H21015012_20240613112601.jpg/https://filer.eco-counter-tools.com/file/6c/7219aac71d6d7c03b90a5eb4b59de532d908084b261509e268a150be6948b76c/Y2H21015012_20250729103525.jpg/https://filer.eco-counter-tools.com/file/9d/176068e8b3503f6b68c846ec1741b3a744b56aede12fa81bfc29fa2c82f96d9d/X2H19027732_20190507110918.jpg/https://filer.eco-counter-tools.com/file/bd/7b7d73a0893fc9813d303fa82a8aec6a2888b910e721b344fe519737bf51e1bd/14997911939232.jpg/https://filer.eco-counter-tools.com/file/cc/7ee37fd33279ac655cb94dac2f5cabe37169064be3d172305eee095aa8eb48cc/Y2H21015012_20220407113640.jpg/https://filer.eco-counter-tools.com/file/cd/d97fc859bef5a19d217f46db0a4ee144cfc19d12fe12a8f8f8d6d837dd05f3cd/Y2H19027732_20210810183209.jpg/https://filer.eco-counter-tools.com/file/d0/1aba92aeca91f0ea6146e062f7994959da2ade84f8c5cded3b9f1e8424ea98d0/15718218590430.jpg/https://filer.eco-counter-tools.com/file/d7/030e39ece3b9677fd4ab1c1de4370b0613ad1c4cafd810f4b06b6489f8304cd7/Y2H21015012_20220803103347.jpg/https://filer.eco-counter-tools.com/file/db/b61f852e0d3afa4b9be0cdcfe0046cb3bb330efa17c3941fae25199cf2134fdb/14997911938171.jpg']<br>
</p>
<p>Nom de la colonne: test_lien_vers_photos_du_site_de_comptage_<br>
 Type : object<br>
Nombre de valeurs uniques : 68<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885175<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['https://filer.eco-counter-tools.com/file/09/73f38aaf49fa85ee19ee67277787a24af6b31b497e0fbf06bf2970b4449a0409/Y2H16029278_20200818121425.jpg'
 'https://filer.eco-counter-tools.com/file/0f/72fcbc343c96fd864d33966e6ca86ed6454fe348c579812ed9c674cf39d1310f/X2H18086316_20240618155704.jpg'
 'https://filer.eco-counter-tools.com/file/4a/2e6127480864e11e9bd152969a114c01c26ea9434bdd7813bc618f511a21b04a/Y2H21015011_20220407110543.jpg'
 'https://filer.eco-counter-tools.com/file/16/35f6b42be906d8dc8ac074b0bfc2683cec4aa3aa4cff6e964ff4a73697ed8816/Y2H21015068_20240618150003.jpg'
 'https://filer.eco-counter-tools.com/file/31/7a51f8668baa67fe9fbc33f577ca62cffa13fab69148810676d42c23d007dc31/15374519009810.jpg']<br>
</p>
<p>Nom de la colonne: id_photo_1<br>
 Type : object<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885242<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['https:' nan]<br>
</p>
<p>Nom de la colonne: url_sites<br>
 Type : object<br>
Nombre de valeurs uniques : 69<br>
Nombre de valeurs manquantes : 24533<br>
Pourcentage de valeurs manquantes : 2.77%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885174<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['https://www.eco-visio.net/Photos/100003098'
 'https://www.eco-visio.net/Photos/100006300'
 'https://www.eco-visio.net/Photos/100007049'
 'https://www.eco-visio.net/Photos/100036718'
 'https://www.eco-visio.net/Photos/100036719']<br>
</p>
<p>Nom de la colonne: type_dimage<br>
 Type : object<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 33582<br>
Pourcentage de valeurs manquantes : 3.79%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885242<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['jpg' nan]<br>
</p>
<p>Nom de la colonne: mois_annee_comptage<br>
 Type : object<br>
Nombre de valeurs uniques : 13<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 885231<br>
soit nb lignes avec un √©l√©ment non unique : 885244<br>
Exemples de valeurs uniques :  ['2024-09' '2024-10' '2024-11' '2024-12' '2025-01']</p>
</div>

<hr class="page-break">

#### <a id="ann2b">Annexe 2b</a> : Structure du jeu de donn√©es m√©t√©o

<div class="two-columns">
<p>Nom de la colonne: NUM_POSTE<br>
 Type : int64<br>
Nombre de valeurs uniques : 6<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3870<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [75106001 75107005 75110001 75114001 75114007]<br>
</p>
<p>Nom de la colonne: NOM_USUEL<br>
 Type : object<br>
Nombre de valeurs uniques : 6<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3870<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  ['LUXEMBOURG' 'TOUR EIFFEL' 'LARIBOISIERE' 'PARIS-MONTSOURIS'
 'PARIS-MONTSOURIS-DOUBLE']<br>
</p>
<p>Nom de la colonne: LAT<br>
 Type : float64<br>
Nombre de valeurs uniques : 5<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3871<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [48.844667 48.858333 48.882833 48.821667 48.854833]<br>
</p>
<p>Nom de la colonne: LON<br>
 Type : float64<br>
Nombre de valeurs uniques : 5<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3871<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [2.333833 2.2945   2.352    2.337833 2.233667]<br>
</p>
<p>Nom de la colonne: ALTI<br>
 Type : int64<br>
Nombre de valeurs uniques : 5<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3871<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 46 330  55  75  27]<br>
</p>
<p>Nom de la colonne: AAAAMMJJ<br>
 Type : int64<br>
Nombre de valeurs uniques : 646<br>
Nombre de valeurs manquantes : 0<br>
Pourcentage de valeurs manquantes : 0.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3230<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [20240101 20240102 20240103 20240104 20240105]<br>
</p>
<p>Nom de la colonne: RR<br>
 Type : float64<br>
Nombre de valeurs uniques : 172<br>
Nombre de valeurs manquantes : 1292<br>
Pourcentage de valeurs manquantes : 33.33%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3703<br>
soit nb lignes avec un √©l√©ment non unique : 3799<br>
Exemples de valeurs uniques :  [9.6 7.1 3.2 0.2 1. ]<br>
</p>
<p>Nom de la colonne: QRR<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 1292<br>
Pourcentage de valeurs manquantes : 33.33%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 1. nan]<br>
</p>
<p>Nom de la colonne: TN<br>
 Type : float64<br>
Nombre de valeurs uniques : 279<br>
Nombre de valeurs manquantes : 9<br>
Pourcentage de valeurs manquantes : 0.23%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3596<br>
soit nb lignes avec un √©l√©ment non unique : 3858<br>
Exemples de valeurs uniques :  [ 6.8  9.  10.4  8.3  6.7]<br>
</p>
<p>Nom de la colonne: QTN<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 9<br>
Pourcentage de valeurs manquantes : 0.23%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3875<br>
Exemples de valeurs uniques :  [ 1. nan  0.]<br>
</p>
<p>Nom de la colonne: HTN<br>
 Type : float64<br>
Nombre de valeurs uniques : 902<br>
Nombre de valeurs manquantes : 20<br>
Pourcentage de valeurs manquantes : 0.52%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 2973<br>
soit nb lignes avec un √©l√©ment non unique : 3532<br>
Exemples de valeurs uniques :  [ 713. 2030. 1750.  801.  807.]<br>
</p>
<p>Nom de la colonne: QHTN<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 20<br>
Pourcentage de valeurs manquantes : 0.52%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 9. nan  1.]<br>
</p>
<p>Nom de la colonne: TX<br>
 Type : float64<br>
Nombre de valeurs uniques : 375<br>
Nombre de valeurs manquantes : 10<br>
Pourcentage de valeurs manquantes : 0.26%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3500<br>
soit nb lignes avec un √©l√©ment non unique : 3833<br>
Exemples de valeurs uniques :  [11.5 12.7 13.  11.6 10.1]<br>
</p>
<p>Nom de la colonne: QTX<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 9<br>
Pourcentage de valeurs manquantes : 0.23%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 1. nan]<br>
</p>
<p>Nom de la colonne: HTX<br>
 Type : float64<br>
Nombre de valeurs uniques : 755<br>
Nombre de valeurs manquantes : 19<br>
Pourcentage de valeurs manquantes : 0.49%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3120<br>
soit nb lignes avec un √©l√©ment non unique : 3613<br>
Exemples de valeurs uniques :  [ 301. 1850. 1137. 1406. 1136.]<br>
</p>
<p>Nom de la colonne: QHTX<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 18<br>
Pourcentage de valeurs manquantes : 0.46%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 9.  1. nan]<br>
</p>
<p>Nom de la colonne: TM<br>
 Type : float64<br>
Nombre de valeurs uniques : 319<br>
Nombre de valeurs manquantes : 21<br>
Pourcentage de valeurs manquantes : 0.54%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3556<br>
soit nb lignes avec un √©l√©ment non unique : 3847<br>
Exemples de valeurs uniques :  [ 8.9 11.4 11.2 10.1  8.1]<br>
</p>
<p>Nom de la colonne: QTM<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 20<br>
Pourcentage de valeurs manquantes : 0.52%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3875<br>
Exemples de valeurs uniques :  [ 1. nan  9.]<br>
</p>
<p>Nom de la colonne: TNTXM<br>
 Type : float64<br>
Nombre de valeurs uniques : 317<br>
Nombre de valeurs manquantes : 10<br>
Pourcentage de valeurs manquantes : 0.26%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3558<br>
soit nb lignes avec un √©l√©ment non unique : 3850<br>
Exemples de valeurs uniques :  [ 9.2 10.9 11.7 10.   8.4]<br>
</p>
<p>Nom de la colonne: QTNTXM<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 10<br>
Pourcentage de valeurs manquantes : 0.26%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 1. nan]<br>
</p>
<p>Nom de la colonne: TAMPLI<br>
 Type : float64<br>
Nombre de valeurs uniques : 199<br>
Nombre de valeurs manquantes : 10<br>
Pourcentage de valeurs manquantes : 0.26%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3676<br>
soit nb lignes avec un √©l√©ment non unique : 3857<br>
Exemples de valeurs uniques :  [4.7 3.7 2.6 3.3 3.4]<br>
</p>
<p>Nom de la colonne: QTAMPLI<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 10<br>
Pourcentage de valeurs manquantes : 0.26%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 1. nan]<br>
</p>
<p>Nom de la colonne: TNSOL<br>
 Type : float64<br>
Nombre de valeurs uniques : 266<br>
Nombre de valeurs manquantes : 2586<br>
Pourcentage de valeurs manquantes : 66.72%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3609<br>
soit nb lignes avec un √©l√©ment non unique : 3840<br>
Exemples de valeurs uniques :  [nan 4.  8.  7.8 5. ]<br>
</p>
<p>Nom de la colonne: QTNSOL<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 2586<br>
Pourcentage de valeurs manquantes : 66.72%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: TN50<br>
 Type : float64<br>
Nombre de valeurs uniques : 219<br>
Nombre de valeurs manquantes : 3232<br>
Pourcentage de valeurs manquantes : 83.38%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3656<br>
soit nb lignes avec un √©l√©ment non unique : 3820<br>
Exemples de valeurs uniques :  [nan 5.4 8.  8.6 6.6]<br>
</p>
<p>Nom de la colonne: QTN50<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 3232<br>
Pourcentage de valeurs manquantes : 83.38%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: DG<br>
 Type : float64<br>
Nombre de valeurs uniques : 193<br>
Nombre de valeurs manquantes : 63<br>
Pourcentage de valeurs manquantes : 1.63%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3682<br>
soit nb lignes avec un √©l√©ment non unique : 3707<br>
Exemples de valeurs uniques :  [   0. 1406. 1440. 1099.  987.]<br>
</p>
<p>Nom de la colonne: QDG<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 63<br>
Pourcentage de valeurs manquantes : 1.63%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ 9. nan  1.]<br>
</p>
<p>Nom de la colonne: FFM<br>
 Type : float64<br>
Nombre de valeurs uniques : 137<br>
Nombre de valeurs manquantes : 1939<br>
Pourcentage de valeurs manquantes : 50.03%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3738<br>
soit nb lignes avec un √©l√©ment non unique : 3853<br>
Exemples de valeurs uniques :  [ nan 13.  16.5 15.3 12.1]<br></p>
<p>Nom de la colonne: QFFM<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 1939<br>
Pourcentage de valeurs manquantes : 50.03%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  1.]<br>
</p>
<p>Nom de la colonne: FF2M<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: QFF2M<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: FXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 182<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3693<br>
soit nb lignes avec un √©l√©ment non unique : 3851<br>
Exemples de valeurs uniques :  [ nan 17.9 23.2 20.7 17.7]<br>
</p>
<p>Nom de la colonne: QFXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  1.]<br>
</p>
<p>Nom de la colonne: DXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 36<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3839<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ nan 200. 210. 240. 250.]<br>
</p>
<p>Nom de la colonne: QDXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: HXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 1003<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 2872<br>
soit nb lignes avec un √©l√©ment non unique : 3404<br>
Exemples de valeurs uniques :  [  nan 2226. 1403. 1343.   37.]<br>
</p>
<p>Nom de la colonne: QHXY<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 1988<br>
Pourcentage de valeurs manquantes : 51.29%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: FXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 245<br>
Nombre de valeurs manquantes : 1939<br>
Pourcentage de valeurs manquantes : 50.03%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3630<br>
soit nb lignes avec un √©l√©ment non unique : 3823<br>
Exemples de valeurs uniques :  [ nan 31.  36.7 29.2 31.7]<br>
</p>
<p>Nom de la colonne: QFXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 1939<br>
Pourcentage de valeurs manquantes : 50.03%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  1.]<br>
</p>
<p>Nom de la colonne: DXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 36<br>
Nombre de valeurs manquantes : 1962<br>
Pourcentage de valeurs manquantes : 50.62%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3839<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [ nan 200. 210. 250. 230.]<br>
</p>
<p>Nom de la colonne: QDXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 1962<br>
Pourcentage de valeurs manquantes : 50.62%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: HXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 990<br>
Nombre de valeurs manquantes : 1963<br>
Pourcentage de valeurs manquantes : 50.64%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 2885<br>
soit nb lignes avec un √©l√©ment non unique : 3409<br>
Exemples de valeurs uniques :  [  nan 2305. 1435. 1334. 1903.]<br>
</p>
<p>Nom de la colonne: QHXI<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 1963<br>
Pourcentage de valeurs manquantes : 50.64%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: FXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: QFXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: DXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: QDXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: HXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: QHXI2<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: FXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 221<br>
Nombre de valeurs manquantes : 1996<br>
Pourcentage de valeurs manquantes : 51.50%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3654<br>
soit nb lignes avec un √©l√©ment non unique : 3833<br>
Exemples de valeurs uniques :  [ nan 29.4 33.2 27.9 30.3]<br>
</p>
<p>Nom de la colonne: QFXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 1<br>
Nombre de valeurs manquantes : 1996<br>
Pourcentage de valeurs manquantes : 51.50%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3874<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  1.]<br>
</p>
<p>Nom de la colonne: DXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: QDXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 0<br>
Nombre de valeurs manquantes : 3876<br>
Pourcentage de valeurs manquantes : 100.00%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3875<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan]<br>
</p>
<p>Nom de la colonne: HXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 961<br>
Nombre de valeurs manquantes : 1997<br>
Pourcentage de valeurs manquantes : 51.52%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 2914<br>
soit nb lignes avec un √©l√©ment non unique : 3414<br>
Exemples de valeurs uniques :  [  nan 2305. 1356. 1334. 1903.]<br>
</p>
<p>Nom de la colonne: QHXI3S<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 1997<br>
Pourcentage de valeurs manquantes : 51.52%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  9.  1.]<br>
</p>
<p>Nom de la colonne: DRR<br>
 Type : float64<br>
Nombre de valeurs uniques : 233<br>
Nombre de valeurs manquantes : 3245<br>
Pourcentage de valeurs manquantes : 83.72%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3642<br>
soit nb lignes avec un √©l√©ment non unique : 3724<br>
Exemples de valeurs uniques :  [ nan 647. 692. 265.  18.]<br>
</p>
<p>Nom de la colonne: QDRR<br>
 Type : float64<br>
Nombre de valeurs uniques : 2<br>
Nombre de valeurs manquantes : 3235<br>
Pourcentage de valeurs manquantes : 83.46%<br>
Nb √©l√©ments utilis√©s plusieurs fois : 3873<br>
soit nb lignes avec un √©l√©ment non unique : 3876<br>
Exemples de valeurs uniques :  [nan  1.  9.]</p>
</div>

<hr class="page-break">

#### <a id="ann2c">Annexe 2c</a> : Notice du jeu de donn√©es du barom√®tre FUB

<div style="text-align:center;">  
  <figure style="display:inline-block; width:92%;">
    <img src="images/notbaro1.png" alt="notice barom√®tre FUB page 1" style="width:100%; display:block;">
  </figure>
</div>

<div style="text-align:center;">  
  <figure style="display:inline-block; width:85%;">
    <img src="images/notbaro2.png" alt="notice barom√®tre FUB page 2" style="width:100%; display:block;">
  </figure>
</div>

<div style="text-align:center;">  
  <figure style="display:inline-block; width:85%;">
    <img src="images/notbaro3.png" alt="notice barom√®tre FUB page 3" style="width:100%; display:block;">
  </figure>
</div>

<div style="text-align:center;">  
  <figure style="display:inline-block; width:100%;">
    <img src="images/notbaro4.png" alt="notice barom√®tre FUB page 4" style="width:100%; display:block;">
  </figure>
</div>

<hr class="page-break">

### <a id="ann3">Annexe 3</a> : Script : superposition des compteurs et clusters du barom√®tre FUB"

_Il s'agit ci-dessous d'extrait de script, certaines variables ayant √©t√© d√©finie pr√©c√©demment dans le code, de m√™me que le dataframe df_geo comptenant les donn√©es des compteurs._

````python
import geopandas as gpd   # manipulation de fichier .geojson et de cooordonn√©es g√©ographiques
import folium as fl  # manipulation interactive de carte
from shapely.geometry import Point   # pour l'affichage de zone sur une carte
from shapely import wkt
from shapely.wkt import loads

# on cr√©√© un champ de g√©om√©trie sur le m√™me format que les jeux de donn√©es du barom√®tre
gdf_compteur = gpd.GeoDataFrame(df_geo, geometry=[Point(xy) for xy in zip(df_geo.longitude, df_geo.latitude)])
gdf_compteur.crs = "EPSG:4326"

# On va centrer la carte sur la moyenne des coordonn√©es des compteurs pour trouver Paris depuis la g√©om√©trie (y = lat, x = lon)
center = [gdf_compteur.geometry.y.mean(), gdf_compteur.geometry.x.mean()]

carte_compteur = fl.Map(location=center, zoom_start=12, tiles='cartodbpositron')

for idx, row in gdf_compteur.iterrows():
    # utiliser la g√©om√©trie de la ligne courante (row) et non la Series enti√®re
    geom = row.get('geometry') if 'geometry' in row.index else None
    if geom is None:
        # on se rabat sur les colonnes latitude/longitude
        if 'latitude' in row.index and 'longitude' in row.index and pd.notnull(row['latitude']) and pd.notnull(row['longitude']):
            lat = float(row['latitude'])
            lon = float(row['longitude'])
        else:
            continue
    else:
        lon = float(geom.x)
        lat = float(geom.y)

    popup_text = row.get('nom_compteur', '') if 'nom_compteur' in row.index else ''
    # utiliser CircleMarker pour pouvoir d√©finir la couleur et le remplissage... on choisit du gris pour ne pas g√™ner l'affichage avec les clusters du
    fl.CircleMarker(
        location=[lat, lon],
        radius=4,
        color='gray',
        fill=True,
        fill_color='gray',
        fill_opacity=0.7,
        popup=popup_text
    ).add_to(carte_compteur)
    
carte_compteur.save('images/carte_compteurs.html')  # cr√©e un fichier html de la carte, restant dynamique (zoom, survol)
display(carte_compteur)  # pour l'affichage dynamique dans le notebook

carte_folium_vers_png(carte_compteur, 'carte_compteurs')
Image(filename='images/carte_compteurs.png')   # affiche la version fig√©e en image de la carte pour l'√©dition en pdf

# on r√©cup√®re les donn√©es des fichiers de clusters de commentaires
liste_clusters_geojson=[]
cl_verts=chemin_user+"data/raw/barometre2025fub-dept75/clusters-verts-75.geojson"
liste_clusters_geojson.append(cl_verts)
cl_rouges=chemin_user+"data/raw/barometre2025fub-dept75/clusters-rouges-75.geojson"
liste_clusters_geojson.append(cl_rouges)
cl_s=chemin_user+"data/raw/barometre2025fub-dept75/clusters-stationnements-75.geojson"
liste_clusters_geojson.append(cl_s)

for f in liste_clusters_geojson:
    fichier_sorti=f[f.find("2025fub-dept75/")+15:f.find(".geojson")]+".csv"
    filepath_sorti=chemin_user+"data/processed/"+fichier_sorti
    df=gpd.read_file(f)
    display(df.head(3))
    df.to_csv(filepath_sorti, sep=";", header=True, index=False, encoding="utf8")

gdf_cl_rouges=pd.read_csv(chemin_user+"data/processed/clusters-rouges-75.csv",sep=";")
gdf_cl_verts=pd.read_csv(chemin_user+"data/processed/clusters-verts-75.csv",sep=";")

gdf_cl_rouges['categorie'] = 'rouge'
gdf_cl_verts['categorie'] = 'vert'
gdf_barometre= pd.concat([gdf_cl_rouges, gdf_cl_verts], ignore_index=True)

# convertir la colonne geometry (WKT - coordonn√©es GPS) en g√©om√©trie shapely puis en GeoDataFrame
gdf_barometre_geo = gpd.GeoDataFrame(
    gdf_barometre.copy(),
    geometry=gdf_barometre['geometry'].apply(wkt.loads),
    crs="EPSG:4326"
)

# on va r√©utiliser la carte des compteurs pour superposer les informations

# style en fonction de la cat√©gorie rouge ou vert (on n'a pas conserv√© les points bleus de stationnement)
def style_function(feature):
    cat = feature['properties'].get('categorie', '').lower()
    color = 'crimson' if cat == 'rouge' else ('green' if cat == 'vert' else 'gray')
    return {
        'fillColor': color,
        'color': color,
        'weight': 1,
        'fillOpacity': 0.4
    }

# ajouter les multipolygons avec popup/tooltip
gj = fl.GeoJson(
    gdf_barometre_geo,
    name='barometre_clusters',
    style_function=style_function,
    tooltip=fl.GeoJsonTooltip(fields=['uid','nb_points','taux_points','categorie'],
                              aliases=['uid','nb_points','taux_points','categorie'],
                              localize=True)
).add_to(carte_compteur)

fl.LayerControl().add_to(carte_compteur)

carte_compteur.save('images/carte_compteurs+clusters.html')  # cr√©e un fichier html de la carte, restant dynamique (zoom, survol)
display(carte_compteur)  # pour l'affichage dynamique dans le notebook

carte_folium_vers_png(carte_compteur, 'carte_compteurs+clusters')
Image(filename='images/carte_compteurs+clusters.png')   # affiche la version fig√©e en image de la carte pour l'√©dition en pdf

````
<hr class="page-break">

### <a id="ann4">Annexes 4</a> : Analyses textuelles

#### <a id="ann4a">Annexe 4a</a> : Normalisation et lemmatisation des avis
````python
import pandas as pd # manipulation de donn√©es
import unicodedata  
import nltk   
from nltk.corpus import stopwords
import spacy  
from spacy_lefff import LefffLemmatizer, POSTagger
from spacy.language import Language

# Chargement de chaque dataset avec gestion automatique de l'encodage
dossier = chemin_user+"data/processed"

def charger_csv(fichier):
    
    chemin = f"{dossier}/{fichier}"
    try:
        return pd.read_csv(chemin, sep=";", encoding="utf-8")
    except UnicodeDecodeError:
        return pd.read_csv(chemin, sep=";", encoding="latin-1")

# Chargement des 3 fichiers contenants des commentaires
points_rouges_75056 = charger_csv("points-rouges-75056.csv")
points_verts_75056 = charger_csv("points-verts-75056.csv")
stationnements_75056 = charger_csv("stationnements-75056.csv")

df_r=points_rouges_75056.copy()
df_r["categorie"]="rouge"

df_v=points_verts_75056.copy()
df_v["categorie"]="vert"

df_s=points_verts_75056.copy()
df_s["categorie"]="stationnement"

# on va concat√©ner les 3 dataframes en un seul
df_comment = pd.concat([df_r, df_v, df_s], ignore_index=True)
df_comment=df_comment.drop(columns=["commune","epci","departement","region"],axis=1)

# et supprimer toutes les lignes sans description
df_comment=df_comment.dropna()

nltk.download("stopwords",quiet=True)  # utile la 1√®re fois si on a une erreur
stop_words = set(stopwords.words('french'))  # on initialise la variable de mots vide sur le fran√ßais
stop_words.update(["v√©lo","rue","route","avenue","boulevard","cyclable","cycliste","√™tre","avoir","c'est","√†","a","vers","bd","cette","quand","vraiment"])

nlp = spacy.load('fr_core_news_md')   # on charge notre mod√®le morphologique fr_core_news_md

if "lefff_lemmatizer" not in Language.factories:
    @Language.factory("lefff_lemmatizer")
    def create_lefff_lemmatizer(nlp, name):
        # si melt_tagger n'est pas initialis√© on peut avoir une erreur '[E046] Can't retrieve unregistered extension attribute 'melt_tagger'. Did you forget to call the set_extension method?'
        # li√© √† un probl√®me de version entre spaCy et spaCy_lefff... d√®s lors qu'on a une version de spaCy >=3.5 (c'est mon cas) car spaCy_lefff est un peu en retard sur la mise √† jour
        # on peut mettre sur False sans risque car il s'agit d'une partie "obsol√®te" de la fonction
        return LefffLemmatizer(after_melt=False)

# Ajouter le pipe seulement s'il n'est pas d√©j√† pr√©sent dans le pipeline (sinon cela va g√©n√©rer une erreur.)
if "lefff_lemmatizer" not in nlp.pipe_names:
    nlp.add_pipe("lefff_lemmatizer", name="lefff_lemmatizer", after="parser")

def lemmatiser_texte(stop_words_fr,texte: str) -> str:
    """
    Nettoie et lemmatise un texte fran√ßais avec spaCy + Lefff.
    Retourne une cha√Æne de caract√®re pr√™te √† √™tre utilis√©e dans un WordCloud ou tout autre analyse.
    """
    if not isinstance(texte, str) or not texte.strip():
        return ""    # on met une condition pour le cas o√π on aurait une lignre dans notre dataframe qui n'aurait pas de commentaires (peu probable puisqu'on a enlev√© les manquants mais plus s√ªr)

    doc = nlp(texte)      # doc n'est pas une cha√Æne de caract√®re, ce sont des ANNOTATIONS √† ce texte. Pour r√©cup√©rer le texte initial on peut ainsi faire doc.text et pour r√©cup√©rer le texte lemmatis√© on va faire doc.lemma_

    # Construction de la cha√Æne lemmatis√©e propre
    chaine_lemmatisee = " ".join(
        token.lemma_.lower()       # on met en minuscule les mots (√ßa peut g√™ner un peu sur les noms propre mais √ßa s√©curise l'application des mots vides sur les d√©buts de phrase par ex)
        for token in doc
        if token.is_alpha               # garder uniquement les mots alphab√©tiques
        and len(token) >= 3                    # √©viter les mots de 1 ou 2 caract√®res
        and token.lemma_.lower() not in stop_words_fr  # supprimer les stop words en partant de la liste mise en argument
    )

    return chaine_lemmatisee

df_comment["commentaire"] = df_comment["description"].apply(lambda x: lemmatiser_texte(stop_words, x))

````
<hr class="page-break">

#### <a id="ann4b">Annexe 4b</a> : Comparaison de 2 algorithmes de cr√©ation de nuage de mot

_L'extrait de script ci-dessous se pla√ßant imm√©diatement apr√®s le pr√©c√©dent, il implique l'utilisation des variables, dataframe et librairie pr√©c√©demment vues._
````python
corpus_vert=df_comment.loc[df_comment.categorie == "vert","commentaire"].astype(str).tolist()
corpus_rouge=df_comment.loc[df_comment.categorie == "rouge","commentaire"].astype(str).tolist()

#----premiers nuages directement sur les cha√Ænes lemmatis√©es------------------------------
nuage_pos = WordCloud(background_color="white", 
               max_words=100, 
               stopwords=stop_words, 
               max_font_size=50,
               random_state=42,
               colormap="viridis") # palette de couleur accessible et adapt√©e √† un sentiment positif
nuage_pos.generate(" ".join(corpus_vert))    # generate attendant une chaine de caract√®re unique, on concat√®ne les √©l√©ments du corpus

nuage_neg = WordCloud(background_color="white", 
               max_words=100, 
               stopwords=stop_words, 
               max_font_size=50,
               random_state=42,
               colormap="inferno") # palette accessible comme viridis mais teintes plus adapt√©es √† un sentiment n√©gatif
nuage_neg.generate(" ".join(corpus_rouge))  # generate attendant une chaine de caract√®re unique, on concat√®ne les √©l√©ments du corpus


# on va afficher c√¥te √† c√¥te les 2 nuages
fig, axes = plt.subplots(1, 2, figsize=(20, 10))

axes[0].imshow(nuage_pos, interpolation='bilinear')
axes[0].set_title("Commentaires positifs", fontsize=18, color="green",y=1.1)
axes[0].axis("off")

axes[1].imshow(nuage_neg, interpolation='bilinear')
axes[1].set_title("Commentaires n√©gatifs", fontsize=18, color="red",y=1.1)
axes[1].axis("off")   # parce que les axes g√¢chent le nuage

#fig.suptitle("Nuages de mots de l'ensemble des commentaires positifs et n√©gatifs", fontsize=20, fontweight="bold", color="#333333", y=0.7)
plt.tight_layout()
plt.show()

#------------deuxi√®me s√©rie de nuages avec algorithme TF_IDF
from sklearn.feature_extraction.text import TfidfVectorizer

# Pour que le vectorisateur fonctionne correctement en fran√ßais, il est n√©cessaire d'appliquer une normalisation suppl√©mentaire
# en supprimant les accents de notre texte afin de ne pas introduire de biais en distinguant par exemple "√©cole" et "ecole".
def supprime_accent(texte : str ) -> str :
    texte = ''.join(
        c for c in unicodedata.normalize('NFD', texte)
        if unicodedata.category(c) != 'Mn'
    )
    return texte

def creer_tfidf_dict(corpus):
    """
    Calcule les poids TF-IDF pour un corpus (liste de textes) et renvoie un dictionnaire {mot: score}.
    Pr√™t √† √™tre utilis√© avec WordCloud.generate_from_frequencies().

    corpus : list[str]  Liste de commentaires (d√©j√† nettoy√©s ou lemmatis√©s).
    """
    corpus_clean = [supprime_accent(texte) for texte in corpus if isinstance(texte, str) and texte.strip()]
    
    if not corpus_clean:
        return {}  # s√©curit√© : √©vite les erreurs sur corpus vide
   
    vectorizer = TfidfVectorizer(
        max_df=0.9,             # ignore les mots trop fr√©quents
        min_df=2,               # ignore les mots trop rares
        norm='l2',              # normalisation standard
    )   
    
    tfidf_matrix = vectorizer.fit_transform(corpus_clean)
    tfidf_scores = np.asarray(tfidf_matrix.mean(axis=0)).ravel()  # on calcule le score moyen de chaque mot
    tfidf_dict = dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))  # on r√©cup√®re ce score dans un dictionnaire qui va nous servir pour le nuage
    return tfidf_dict

# et on g√©n√®re nos nuages c√¥te √† c√¥te
nuage_pos = WordCloud(background_color="white", 
               max_words=100, 
               stopwords=stop_words, 
               max_font_size=50,
               random_state=42,
               colormap="viridis") # palette de couleur accessible et adapt√©e √† un sentiment positif
nuage_pos.generate_from_frequencies(creer_tfidf_dict(corpus_vert))

nuage_neg = WordCloud(background_color="white", 
               max_words=100, 
               stopwords=stop_words, 
               max_font_size=50,
               random_state=42,
               colormap="inferno") # palette accessible comme viridis mais teintes plus adapt√©es √† un sentiment n√©gatif
nuage_neg.generate_from_frequencies(creer_tfidf_dict(corpus_rouge))

# on va afficher c√¥te √† c√¥te les 2 nuages
fig, axes = plt.subplots(1, 2, figsize=(20, 10))

axes[0].imshow(nuage_pos, interpolation='bilinear')
axes[0].set_title("Commentaires positifs", fontsize=18, color="green",y=1.1)
axes[0].axis("off")

axes[1].imshow(nuage_neg, interpolation='bilinear')
axes[1].set_title("Commentaires n√©gatifs", fontsize=18, color="red",y=1.1)
axes[1].axis("off")   # parce que les axes g√¢chent le nuage

#fig.suptitle("Nuages de mots de l'ensemble des commentaires positifs et n√©gatifs", fontsize=20, fontweight="bold", color="#333333", y=0.7)
plt.tight_layout()
plt.show()

````
<hr class="page-break">

### <a id="ann5">Annexes 5</a> : Jointure g√©ospatiale des commentaires et compteurs

#### <a id="ann5a">Annexe 5b</a> : Script de d√©termination du rayon seuil de proximit√©

```python

import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from shapely import wkt
from shapely.wkt import loads
import os

# --- 1. CHEMINS VERS LES FICHIERS ---
path_pts_compteurs = "../data/processed/compteurs_velo.csv"
path_points_rouges = "../data/processed/points-rouges-75056.csv"
path_points_verts  = "../data/processed/points-verts-75056.csv"

# V√©rification rapide pour s'assurer que les fichiers existent
for path in [path_pts_compteurs, path_points_rouges, path_points_verts]:
    print(path, "existe ?", os.path.exists(path))

# --- 2. SYST√àMES DE COORDONN√âES ---
CRS_GEO    = "EPSG:4326"  # WGS84 (lat/lon) pour la lecture
CRS_METRIC = "EPSG:2154"  # Lambert-93 (m√®tres) pour les calculs

# --- 3. CHARGEMENT ET PR√âPARATION DES DONN√âES ---

# Compteurs de v√©los (avec longitude / latitude)
df_compteurs = pd.read_csv(path_pts_compteurs, sep=';', encoding='latin1')
gdf_compteurs = gpd.GeoDataFrame(
    df_compteurs, 
    geometry=gpd.points_from_xy(df_compteurs.longitude, df_compteurs.latitude),
    crs=CRS_GEO
)

# Points rouges (colonne geometry d√©j√† pr√©sente en WKT)
df_rouges = pd.read_csv(path_points_rouges, sep=';', encoding='latin1')
df_rouges['geometry'] = df_rouges['geometry'].apply(wkt.loads)
gdf_rouges = gpd.GeoDataFrame(df_rouges, geometry='geometry', crs=CRS_GEO)

# Points verts (colonne geometry d√©j√† pr√©sente en WKT)
df_verts = pd.read_csv(path_points_verts, sep=';', encoding='latin1')
df_verts['geometry'] = df_verts['geometry'].apply(wkt.loads)
gdf_verts = gpd.GeoDataFrame(df_verts, geometry='geometry', crs=CRS_GEO)

# S'assurer d'un point unique par id_site pour les compteurs
pts_sorted = gdf_compteurs.sort_values(['id_site', 'nom_compteur'])
pts_unique = (
    pts_sorted
    .groupby('id_site', as_index=False)
    .first()
)
pts_unique = gpd.GeoDataFrame(pts_unique, geometry='geometry', crs=CRS_GEO)

# --- 4.  Plage de rayons √† tester (en m√®tres)
rayons_a_tester = np.arange(25, 301, 25)  # De 25m √† 300m, par pas de 25m
print(f"Rayons qui seront test√©s : {rayons_a_tester}")

resultats_sensibilite = []

# On boucle sur chaque rayon
for rayon in rayons_a_tester:
    # On cr√©e les buffers avec le rayon actuel
    gdf_buffers = pts_unique_metric.copy()
    gdf_buffers['geometry'] = gdf_buffers.geometry.buffer(rayon)

    # Jointure pour les points ROUGES
    jointure_r = gpd.sjoin(gdf_rouges_metric, gdf_buffers, how='inner', predicate='within')
    sites_uniques_r = jointure_r['id_site'].nunique()
    
    # Jointure pour les points VERTS
    jointure_v = gpd.sjoin(gdf_verts_metric, gdf_buffers, how='inner', predicate='within')
    sites_uniques_v = jointure_v['id_site'].nunique()
    
    # On stocke les r√©sultats
    resultats_sensibilite.append({
        'rayon_m': rayon,
        'nb_sites_rouges': sites_uniques_r,
        'nb_sites_verts': sites_uniques_v
    })

# On convertit les r√©sultats en DataFrame pour une analyse facile
df_resultats = pd.DataFrame(resultats_sensibilite)

print("\nTableau des r√©sultats de sensibilit√© :")
print(df_resultats)


# ---5. Visualisation des r√©sultats ---
plt.figure(figsize=(12, 7))
plt.plot(df_resultats['rayon_m'], df_resultats['nb_sites_rouges'], marker='o', linestyle='-', label='Sites associ√©s √† des Points Rouges')
plt.plot(df_resultats['rayon_m'], df_resultats['nb_sites_verts'], marker='o', linestyle='-', label='Sites associ√©s √† des Points Verts')

plt.title('Analyse de Sensibilit√© du Rayon de Proximit√©')
plt.xlabel('Rayon de recherche (m√®tres)')
plt.ylabel("Nombre de sites de comptage uniques avec au moins 1 correspondance")
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.xticks(rayons_a_tester)
plt.legend()
plt.show()
```
<hr class="page-break">

#### <a id="ann5b">Annexe 5b</a> : Script de Jointure g√©ospatiale

```python
# 1. PARAM√àTRES ET CHEMINS

path_commentaires = '../data/processed/commentaires.csv'  # incluant la colonne de lemmes
path_compteurs = '../data/processed/compteurs_velo.csv'
path_sortie = '../data/processed/commentaires_enrichis_sites.csv'

# D√©finition des syst√®mes de coordonn√©es
CRS_GEO = "EPSG:4326"  # WGS84 (syst√®me GPS latitude/longitude)
CRS_METRIC = "EPSG:2154"  # Lambert-93 (m√®tres - France m√©tropolitaine)
SEUIL_DISTANCE = 125      # Seuil pour retenir un commentaire

# 2. FONCTION UTILITAIRE 

def load_gdf_from_wkt_csv(path_csv: str,encodage:str) -> gpd.GeoDataFrame:
    """Charge un CSV qui a une colonne 'geometry' en format WKT."""
    df = pd.read_csv(path_csv, sep=';',encoding=encodage)
    geom = df['geometry'].apply(wkt.loads)
    gdf = gpd.GeoDataFrame(df, geometry=geom, crs=CRS_GEO)
    return gdf

# 3. CHARGEMENT ET PR√âPARATION

# Charger les commentaires
gdf_commentaires = load_gdf_from_wkt_csv(path_commentaires,'utf8')

# Charger les compteurs et cr√©er les sites uniques (1 point par id_site)
gdf_compteurs_brut = load_gdf_from_wkt_csv(path_compteurs,'latin-1')
pts_sorted = gdf_compteurs_brut.sort_values(['id_site', 'nom_compteur'])
gdf_sites_uniques = (
    pts_sorted
    .groupby('id_site', as_index=False)
    .first()
)
gdf_sites_uniques = gpd.GeoDataFrame(gdf_sites_uniques, geometry='geometry', crs=CRS_GEO)

print(f"Charg√© {len(gdf_commentaires)} commentaires.")
print(f"Charg√© {len(gdf_sites_uniques)} sites de comptage uniques.")

# 4. REPROJECTION EN M√âTRIQUE
# Obligatoire pour sjoin_nearest pour calculer les distances en m√®tres
gdf_commentaires_metric = gdf_commentaires.to_crs(CRS_METRIC)
gdf_sites_metric = gdf_sites_uniques.to_crs(CRS_METRIC)

# 5. JOINTURE "PLUS PROCHE VOISIN" 
jointure_proximite = gpd.sjoin_nearest(
    gdf_commentaires_metric,   # Ce qu'on veut enrichir (√† gauche)
    gdf_sites_metric,          # Ce qu'on cherche (√† droite)
    how='left',
    distance_col='distance_au_site_m' # Cr√©e la colonne de distance
)

# 6. NETTOYAGE ET ENRICHISSEMENT DU R√âSULTAT

# On s√©lectionne les colonnes d'origine + celles de la jointure
cols_origine = [col for col in gdf_commentaires.columns if col != 'geometry']
cols_ajoutees = ['id_site', 'nom_site', 'distance_au_site_m','id_compteur']
resultat_final_metric = jointure_proximite[cols_origine + cols_ajoutees + ['geometry']]

# Renommage pour plus de clart√©
resultat_final_metric = resultat_final_metric.rename(columns={
    'id_site': 'site_plus_proche_id',
    'nom_site': 'site_plus_proche_nom',
    'id_compteur':'compteur_plus_proche_id'
})

# Ajout de la colonne 'statut_proximite'
resultat_final_metric['statut_proximite'] = np.where(
    resultat_final_metric['distance_au_site_m'] <= SEUIL_DISTANCE,
    'retenu',
    'non retenu'
)

# --- 7. REPROJECTION FINALE ET V√âRIFICATION ---
resultat_final_wgs84 = resultat_final_metric.to_crs(CRS_GEO)

print("\nAper√ßu du r√©sultat final :")
print(resultat_final_wgs84[[
    'commentaire',
    'categorie',
    'site_plus_proche_nom',
    'distance_au_site_m',
    'statut_proximite'
]].head())

# 8. EXPORT
# Exporte le CSV enrichi (en convertissant la g√©om√©trie en WKT)
resultat_final_wgs84['geometry'] = resultat_final_wgs84.geometry.to_wkt()
resultat_final_wgs84.drop(columns=['geometry']).to_csv(
    path_sortie,
    sep=';',
    index=False,
    encoding='utf-8-sig'
)
```

<hr class="page-break">

### <a id="ann6">Annexe 6</a> : Transformation des adresses et gestion de l'encodage

```lua
let
  Url = "https://api.github.com/repos/marieberthiau/trafic_cycliste_a_Paris/contents/data/processed/compteurs_velo.csv?ref=main",
  Token = tokenGitHub,   /* mis en param√®tes Power BI */
  Raw = Web.Contents(Url, [  Headers=[
            Authorization = "token " & Token,
            Accept = "application/vnd.github.v3.raw" ] ] ),
SourceFileBinary = Raw,

  // Petite fonction utilitaire pour lire + pr√©parer en un encodage donn√©
ReadCsvWithEncoding = (binary as binary, enc as number) as table =>
    let
        Raw = Csv.Document(binary, [Delimiter=";", Encoding=enc, QuoteStyle=QuoteStyle.Csv]),
        Promoted = Table.PromoteHeaders(Raw, [PromoteAllScalars=true]),
        AsText = Table.TransformColumnTypes(Promoted, List.Transform(Table.ColumnNames(Promoted), each {_, type text})),
        Trimmed = Table.TransformColumns(AsText, List.Transform(Table.ColumnNames(AsText), each {_, Text.Trim})),
        Cleaned = Table.TransformColumns(Trimmed, List.Transform(Table.ColumnNames(Trimmed), each {_, Text.Clean}))
    in
        Cleaned,

  // Lire en UTF-8
T_utf8 = ReadCsvWithEncoding(SourceFileBinary, 65001),

  // Heuristique : compter les ‚ÄúÔøΩ‚Äù (caract√®re de remplacement) dans toutes les colonnes texte
  CountReplacementChar = (tbl as table) as number =>
    let
      cols = Table.ColumnNames(tbl),
      lists = List.Transform(cols, each Table.Column(tbl, _)),
      countPerCol = List.Transform(lists, each List.Sum(List.Transform(_, (v) => if (v is text) and Text.Contains(v, "ÔøΩ") then 1 else 0))),
      total = List.Sum(countPerCol)
    in
      total,

badUtf8 = CountReplacementChar(T_utf8),

  // Si on d√©tecte des ‚ÄúÔøΩ‚Äù, on relit en CP1252 (Windows-1252)
T_best = if badUtf8 > 0 then ReadCsvWithEncoding(SourceFileBinary, 1252) else T_utf8,

  // --------- Reconstruction Latitude/Longitude ----------
  // Normaliser d√©cimales √©ventuelles "48,85" -> "48.85"
  WithLatNorm = if List.Contains(Table.ColumnNames(T_best), "latitude")
                then Table.AddColumn(T_best, "_lat_norm", each if [latitude] <> null then Text.Replace([latitude], ",", ".") else null)
                else Table.AddColumn(T_best, "_lat_norm", each null),

  WithLonNorm = if List.Contains(Table.ColumnNames(WithLatNorm), "longitude")
                then Table.AddColumn(WithLatNorm, "_lon_norm", each if [longitude] <> null then Text.Replace([longitude], ",", ".") else null)
                else Table.AddColumn(WithLatNorm, "_lon_norm", each null),

  // Extraire depuis 'coordonnees' "lat, lon" si vide
  WithCoordParts =
      Table.AddColumn(WithLonNorm, "_coord_parts", each
        let c = try [coordonnees] otherwise null
        in  if c <> null then
              List.Transform(List.Select(Text.SplitAny(Text.Replace(c, ",", "."), " "), each _ <> ""), each _)
            else null),

  // Choisir la meilleure source pour Lat/Lon
  WithLat = Table.AddColumn(WithCoordParts, "Latitude", each
              let v = if [ _lat_norm ] <> null and [ _lat_norm ] <> "" then [ _lat_norm ]
                      else if [ _coord_parts ] <> null and List.Count([ _coord_parts ]) >= 1 then [ _coord_parts ]{0}
                      else null
              in try Number.FromText(v, "en-US") otherwise null, type number),

  WithLon = Table.AddColumn(WithLat, "Longitude", each
              let v = if [ _lon_norm ] <> null and [ _lon_norm ] <> "" then [ _lon_norm ]
                      else if [ _coord_parts ] <> null and List.Count([ _coord_parts ]) >= 2 then [ _coord_parts ]{1}
                      else null
              in try Number.FromText(v, "en-US") otherwise null, type number),

  // --------- date_installation robuste ----------
  WithDateInstall =
    Table.AddColumn(WithLon, "date_installation_dt",
      each let s = try [date_installation] otherwise null
           in  if s = null then null
               else
                 let tryZ = try DateTimeZone.From(s) otherwise null
                 in  if tryZ <> null then DateTimeZone.RemoveZone(tryZ)
                     else (try DateTime.FromText(s, "fr-FR") otherwise null),
      type datetime),

  // --------- Typage final (et garder les accents corrects) ----------
  Typed = Table.TransformColumnTypes(WithDateInstall,{ {"id_compteur", type text},{"nom_compteur", type text},{"id_site", type text},{"nom_site", type text},{"photo_site", type text},{"coordonnees", type text},{"id_technique_compteur", type text},{"ID Photos", type text}, {"test_lien_vers_photos_du_site_de_comptage_", type text},{"id_photo_1", type text},
        {"url_sites", type text},{"type_dimage", type text},{"geometry", type text}, {"date_installation_dt", type datetime},{"Latitude", type number}{"Longitude", type number} },  "fr-FR"  ),

  // Supprimer colonnes techniques temporaires ; remplacer l‚Äôancienne date_installation si tu veux
  DropTemps = Table.RemoveColumns(Typed, {"_lat_norm","_lon_norm","_coord_parts"}),
  Result =
      if List.Contains(Table.ColumnNames(DropTemps), "date_installation") then
          Table.RenameColumns(
              Table.RemoveColumns(DropTemps, {"date_installation"}),
              {{"date_installation_dt", "date_installation"}}
          )
      else
          Table.RenameColumns(DropTemps, {{"date_installation_dt", "date_installation"}}),

  // R√©ordonner des colonnes cl√© en t√™te
  Final = Table.ReorderColumns(
            Result,
            List.Intersect({
              {"id_compteur","nom_compteur","id_site","nom_site","date_installation","id_technique_compteur","ID Photos","photo_site","url_sites","coordonnees","Latitude","Longitude","geometry"},
              Table.ColumnNames(Result)
            })
          ),
    #"Type modifi√©" = Table.TransformColumnTypes(Final,{{"date_installation", type date}}),
    #"Colonnes supprim√©es" = Table.RemoveColumns(#"Type modifi√©",{"longitude", "coordonnees", "latitude"}),
    #"Colonnes renomm√©es" = Table.RenameColumns(#"Colonnes supprim√©es",{{"geometry", "coordonn√©es"}}),
    #"Colonnes permut√©es" = Table.ReorderColumns(#"Colonnes renomm√©es",{"id_compteur", "nom_compteur", "id_site", "nom_site", "date_installation", "id_technique_compteur", "ID Photos", "photo_site", "test_lien_vers_photos_du_site_de_comptage_", "id_photo_1", "url_sites", "type_dimage", "coordonn√©es", "Latitude", "Longitude"}),
    #"Renamed Columns" = Table.RenameColumns(#"Colonnes permut√©es",{{"date_installation", "Date d'installation"}}),
    #"Replaced Value2" = Table.ReplaceValue(#"Renamed Columns","Totem","[totem]",Replacer.ReplaceText,{"nom_compteur", "nom_site"}),
    
    // on raccourcit le nom du site pour am√©liorer la lisibilit√© ds filtres (sinon on ne voit que des trucs style 106 boulevard.... au lieu du nom de la rue
    RaccourciNomDuSite = Table.AddColumn(#"Replaced Value2", "Site de comptage", 
      each let
        txt = Text.Trim([nom_site]),
        posMaj = Text.PositionOfAny(txt, {"A".."Z","√â","√à","√ä","√ã","√Ä","√Ç","√Ñ","√î","√ñ","√ô","√õ","√ú","√á"}),
        Result =
            if posMaj >1 then
                let
                    gauche = Text.Start(txt, posMaj),
                    droite = Text.End(txt, Text.Length(txt) - posMaj)
                in
                    Text.Trim(Text.Combine({droite, " (", gauche, ")"}))
            else
                txt
          in
            Result),

    #"Added Custom Column" = Table.AddColumn(RaccourciNomDuSite, "Custom", each let splitNomducompteur = List.Reverse(Splitter.SplitTextByDelimiter(" ", QuoteStyle.None)([nom_compteur])) in splitNomducompteur{0}?, type text),

    #"Duplicated Column" = Table.DuplicateColumn(#"Added Custom Column", "Site de comptage", "Site de comptage - Copy"),
    #"Reordered Columns" = Table.ReorderColumns(#"Duplicated Column",{"Site de comptage - Copy", "Custom"}),
    #"Merged Columns" = Table.CombineColumns(#"Reordered Columns",{"Site de comptage - Copy", "Custom"},Combiner.CombineTextByDelimiter(" ", QuoteStyle.None),"Nom du compteur"),
    #"Replaced Value" = Table.ReplaceValue(#"Merged Columns","avenue","av",Replacer.ReplaceText,{"Site de comptage", "Nom du compteur"}),
    #"Replaced Value1" = Table.ReplaceValue(#"Replaced Value","boulevard","bd",Replacer.ReplaceText,{"Site de comptage", "Nom du compteur"}),
    #"Removed Columns" = Table.RemoveColumns(#"Replaced Value1",{"nom_compteur", "nom_site", "id_technique_compteur", "ID Photos", "test_lien_vers_photos_du_site_de_comptage_", "id_photo_1", "type_dimage"}),
    #"Filtered Rows" = Table.SelectRows(#"Removed Columns", each ([id_site] <> "100003098" and [id_site] <> "300030116"))  //compteur Denfert Rochereau ne renvoie aucun comptage et compteur 24 Jourdan s'arr√™te d√©but oct 2024.
    // reste √† traiter le 147 av d'Italie du 30 juillet au 4 ao√ªt 2025 inclus : remplacer valeurs actuelles par les moyennes horaires (calculer sur base de juin + % de baisse de fr√©quentation iso 180 av d'Italie entre juin et la m√™me p√©riode d'ao√ªt)
in
    #"Filtered Rows"
```
<hr class="page-break">

### <a id="ann7">Annexe 7</a> : Colonnes calcul√©es de score m√©t√©o

```lua
let
    Url="https://api.github.com/repos/marieberthiau/trafic_cycliste_a_Paris/contents/data/processed/meteo.csv?ref=main",
    Token=tokenGitHub,
    Raw = Web.Contents(
        Url,
        [
            Headers=[Authorization = "token " & Token, Accept = "application/vnd.github.v3.raw"]
        ]
    ),
    CSVText = Text.FromBinary(Raw),
    SourceTable=Csv.Document(CSVText,[Delimiter=";", Encoding=65001, QuoteStyle=QuoteStyle.Csv]),
    EnTetes = Table.PromoteHeaders(SourceTable, [PromoteAllScalars=true]),
    #"Replaced Value1" = Table.ReplaceValue(EnTetes,"",(each _ [#"FXI force max instantan√©e du vent √† 10m (m/s)"]),Replacer.ReplaceValue,{"FXI3S force max quotidienne sur 3sec du vent √† 10m (m/s)"}),
    // Colonnes utiles
    ColonnesUtiles = Table.SelectColumns(#"Replaced Value1", {"AAAAMMJJ", "RR pr√©cipitations (mm)", "TX temp. max (¬∞C)","TN temp. mini (¬∞C)", "TM", "FFM force moyenne sur 10mn du vent √† 10m (m/s)","DRR dur√©e de pr√©cipitations (mn)","FXI3S force max quotidienne sur 3sec du vent √† 10m (m/s)"
    }),
    // Renommage court
    RenomsCourts = Table.RenameColumns(ColonnesUtiles, { {"AAAAMMJJ", "date_raw"},{"RR pr√©cipitations (mm)", "Pr√©cipitations (mm)"}, {"TX temp. max (¬∞C)", "Temp√©rature Max (¬∞C)"}, {"TN temp. mini (¬∞C)", "Temp√©rature Mini (¬∞C)"}, {"TM", "Temp√©rature Moyenne (¬∞C)"},{"FFM force moyenne sur 10mn du vent √† 10m (m/s)", "FFM_ms"},{"FXI3S force max quotidienne sur 3sec du vent √† 10m (m/s)", "FXI3S_ms"},{"DRR dur√©e de pr√©cipitations (mn)", "Dur√©e Pluie (min)"}  }),

    // Nettoyage espaces & textes
    NBSP = Character.FromNumber(160),
    CleanText = (t as any) as nullable text => let s = if t=null then null else Text.From(t) in Text.Trim(Text.Replace(s, NBSP, "")),
    ToTextTrim = Table.TransformColumns(RenomsCourts, List.Transform(Table.ColumnNames(RenomsCourts), each {_, each CleanText(_), type text})),

    // Conversion date
    DateParsed = Table.AddColumn(ToTextTrim, "date", each try Date.FromText(Text.Start(Text.Select([date_raw], {"0".."9"}),8)) otherwise null, type date),

    // Conversion nombres
    ConvertNum = Table.TransformColumns(DateParsed, {
        {"Pr√©cipitations (mm)", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"Temp√©rature Max (¬∞C)", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"Temp√©rature Mini (¬∞C)", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"Temp√©rature Moyenne (¬∞C)", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"FFM_ms", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"FXI3S_ms", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number},
        {"Dur√©e Pluie (min)", each Number.FromText(Text.Replace(_, ",","."), "en-US"), type number}
    }),
    #"Replaced Value" = Table.ReplaceValue(ConvertNum,null,0,Replacer.ReplaceValue,{"Dur√©e Pluie (min)"}),

    // Calculs utiles
    Add_FFM_kmh = Table.AddColumn(#"Replaced Value", "Vent Moyen (km/h)", each [FFM_ms]*3.6, type number),
    Add_FXI3S_kmh = Table.AddColumn(Add_FFM_kmh, "Rafale Max (km/h)", each [FXI3S_ms]*3.6, type number),
    Add_Amp=Table.AddColumn(Add_FXI3S_kmh, "Amplitude Thermique", each [#"Temp√©rature Max (¬∞C)"]-[#"Temp√©rature Mini (¬∞C)"], type number),
    Add_NP=Table.AddColumn(Add_Amp, "Niveau Pluie", each [#"Pr√©cipitations (mm)"]+ ([#"Dur√©e Pluie (min)"]/60)/2, type number),

    CatPluie = Table.AddColumn(Add_NP, "Cat Pluie", each if [#"Niveau Pluie"] = null then "Autre" 
                    else if [#"Niveau Pluie"] = 0 then "temps sec" 
                    else if [#"Niveau Pluie"] <= 1 then "bruine" 
                    else if [#"Niveau Pluie"] <= 3 then "pluie faible" 
                    else if [#"Niveau Pluie"] <= 7 then "pluie mod√©r√©e : √©quipement n√©cessaire" 
                    else if [#"Niveau Pluie"] <= 12 then "pluie forte : conditions difficiles" 
                    else "pluie dangereuse : cyclisme d√©conseill√©", 
                        type text ),

    OrdreCatPluie = Table.AddColumn(CatPluie, "Ordre Cat Pluie", each if [#"Niveau Pluie"] = null then "Z" 
                    else if [#"Niveau Pluie"] = 0 then "A" 
                    else if [#"Niveau Pluie"] <= 1 then "B" 
                    else if [#"Niveau Pluie"] <= 3 then "C" 
                    else if [#"Niveau Pluie"] <= 7 then "D" 
                    else if [#"Niveau Pluie"] <= 12 then "E" 
                    else "F", 
                        type text ),

    ScorePluie = Table.AddColumn(OrdreCatPluie, "Score Pluie", each if [#"Niveau Pluie"] = 0 then 40
                    else if [#"Niveau Pluie"] >= 15 then 0
                    else Number.Round(40 - ([#"Niveau Pluie"] * 40 / 15),0),
                                                        Int64.Type),

    ScoreTemp = Table.AddColumn(ScorePluie, "Score Temp√©rature", each 
            let
                TM = [#"Temp√©rature Moyenne (¬∞C)"],
                TMin = [#"Temp√©rature Mini (¬∞C)"],
                TMax = [#"Temp√©rature Max (¬∞C)"],
                Amplitude = [#"Amplitude Thermique"],
                ScoreTempMoyenne = 
                if TM < 5 then List.Max({10, TM * 2})
                  else if TM < 10 then 18 + (TM - 5) * 2
                  else if TM < 15 then 28 + (TM - 10) * 2.4
                  else if TM <= 22 then 40
                  else if TM <= 27 then 40 - (TM - 22) * 2 
                  else if TM <= 30 then 30 - (TM - 27) * 3    
                  else if TM <= 35 then 18 - (TM - 30) * 3
                  else List.Max({0, 3 - (TM - 35) * 0.6}), /*progression plus punitive sur les fortes chaleurs*/
                PenaliteFroid = 
                if TMin < -5 then 5
                  else if TMin < 0 then 3
                  else if TMin < 5 then 1
                  else 0,
                PenaliteChaud =  
                if TMax > 35 then 5
                  else if TMax > 32 then 3
                  else if TMax > 28 then 1
                  else 0,
                PenaliteAmplitude =  
                if Amplitude > 18 then 3
                  else if Amplitude > 14 then 2
                  else if Amplitude > 10 then 1
                  else 0
              in
                Number.Round(ScoreTempMoyenne - PenaliteFroid - PenaliteChaud - PenaliteAmplitude, 0),
                      Int64.Type), /*pour un trajet matin/soir, on subit potentiellement les 2 extr√™mes de temp√©rature*/

    CatTemp = Table.AddColumn(ScoreTemp, "Cat Temp√©rature", each if ( [#"Temp√©rature Mini (¬∞C)"] < -2 or [#"Temp√©rature Moyenne (¬∞C)"] < 3 ) then "froid extr√™me" 
            else if ( [#"Temp√©rature Mini (¬∞C)"] < 5 or [#"Temp√©rature Moyenne (¬∞C)"] < 10 ) then "froid mais g√©rable" 
            else if ( [#"Temp√©rature Moyenne (¬∞C)"] >=10 and [#"Temp√©rature Moyenne (¬∞C)"] < 15 ) then "frais" 
            else if ( [#"Temp√©rature Moyenne (¬∞C)"] >=15 and [#"Temp√©rature Moyenne (¬∞C)"] <= 25 and [#"Temp√©rature Max (¬∞C)"] <= 28 )  then "doux" 
            else if (( [#"Temp√©rature Moyenne (¬∞C)"] >22 and [#"Temp√©rature Moyenne (¬∞C)"] <= 28 ) or ( [#"Temp√©rature Max (¬∞C)"] >28 and [#"Temp√©rature Max (¬∞C)"] <= 32 ) ) then "chaud" 
            else if ([#"Temp√©rature Moyenne (¬∞C)"] >28 or [#"Temp√©rature Max (¬∞C)"] > 32) then "tr√®s chaud" 
            else "Autre", 
              type text ),
    OrdreCatTemp = Table.AddColumn(CatTemp, "Ordre Cat Temp√©rature", each if [#"Cat Temp√©rature"] = null then "Z" 
            else if [#"Cat Temp√©rature"] ="froid extr√™me" then "A" 
            else if [#"Cat Temp√©rature"] ="froid mais g√©rable" then "B" 
            else if [#"Cat Temp√©rature"] ="frais" then "C" 
            else if [#"Cat Temp√©rature"] ="doux" then "D" 
            else if [#"Cat Temp√©rature"] ="chaud" then "E" 
            else "F", 
              type text ),

    ScoreVent = Table.AddColumn(OrdreCatTemp, "Score Vent", each 
                  let
                        Vent = [#"Vent Moyen (km/h)"],
                        Rafale = [#"Rafale Max (km/h)"],
                         ScoreVent = 
                  if Vent < 10 then 15
                    else if Vent > 30 then 0
                    else 15 - (Vent-10) * 15/(30-10),  // progression lin√©aire entre 10 et 30 km/h 
                                                        ScoreRafale = 
                  if Rafale < 30 then 5
                    else if Rafale > 70 then 0
                    else 5 - (Rafale-30) * 5/(70-30)   // progression lin√©aire entre 30 et 70 km/h           
                  in
                   Number.Round(ScoreVent + ScoreRafale,0),  //le vent moyen seul ne permet pas de cat√©goriser les conditions de cyclabilit√©
                                        Int64.Type), 

    CatVent = Table.AddColumn(ScoreVent, "Cat Vent", each if ( [#"Vent Moyen (km/h)"] >= 40 or [#"Rafale Max (km/h)"] >= 75 or ( [#"Vent Moyen (km/h)"] >= 30 and [#"Rafale Max (km/h)"] >= 65 ) ) then "temp√©tueux cyclisme d√©conseill√©" 
                    else if ( [#"Vent Moyen (km/h)"] >= 30 or [#"Rafale Max (km/h)"] >= 60 or ( [#"Vent Moyen (km/h)"] >= 25 and [#"Rafale Max (km/h)"] >= 55 ) ) then "tr√®s fort et dangereux" 
                    else if ( [#"Vent Moyen (km/h)"] >= 20 and [#"Rafale Max (km/h)"] >= 50 ) then "p√©nible mais praticable"
                    else if ( [#"Vent Moyen (km/h)"] >= 15 and [#"Rafale Max (km/h)"] >= 40 ) then "mod√©r√© mais commence √† g√™ner"
                    else if ( [#"Vent Moyen (km/h)"] >= 10 and [#"Rafale Max (km/h)"] >= 30 ) then "l√©ger mais acceptable"
                    else "calme id√©al", type text ),

    OrdreCatVent = Table.AddColumn(CatVent, "Ordre Cat Vent", each if [#"Cat Vent"] = "calme id√©al" then "A" 
                    else if [#"Cat Vent"] = "l√©ger mais acceptable" then "B" 
                    else if [#"Cat Vent"] = "mod√©r√© mais commence √† g√™ner" then "C" 
                    else if [#"Cat Vent"] = "p√©nible mais praticable" then "D"
                    else if [#"Cat Vent"] = "tr√®s fort et dangereux" then "E"  
                    else "F", type text ),

    ScoreMeteo = Table.AddColumn(OrdreCatVent, "Score M√©t√©o", each [#"Score Pluie"]+[#"Score Temp√©rature"]+[#"Score Vent"],Int64.Type), 

    CatConditions = Table.AddColumn(ScoreMeteo, "Conditions Globales", each if [#"Score M√©t√©o"] = null then "inconnues" 
                    else if [#"Score M√©t√©o"] >= 80 then "excellentes" 
                    else if [#"Score M√©t√©o"] >= 60 then "bonnes" 
                    else if [#"Score M√©t√©o"] >= 40 then "acceptables" 
                    else if [#"Score M√©t√©o"] >= 20 then "difficiles" 
                    else "tr√®s difficiles", type text ), 

    OrdreCatConditions = Table.AddColumn(CatConditions, "Ordre Conditions Globales", each if [#"Score M√©t√©o"] = null then "Z"
                    else if [#"Score M√©t√©o"] >= 80 then "A" 
                    else if [#"Score M√©t√©o"] >= 60 then "B" 
                    else if [#"Score M√©t√©o"] >= 40 then "C" 
                    else if [#"Score M√©t√©o"] >= 20 then "D" 
                    else "E", type text ),

    Suppr = Table.RemoveColumns(OrdreCatConditions, {"FFM_ms","FXI3S_ms","date_raw"}),
    Sortie = Table.SelectRows(Suppr, each [date] <> null),
    Final = Table.ReorderColumns(Sortie,{"date","Pr√©cipitations (mm)","Dur√©e Pluie (min)","Cat Pluie","Ordre Cat Pluie","Temp√©rature Mini (¬∞C)","Temp√©rature Max (¬∞C)","Amplitude Thermique","Temp√©rature Moyenne (¬∞C)","Score Temp√©rature","Cat Temp√©rature","Ordre Cat Temp√©rature","Vent Moyen (km/h)","Rafale Max (km/h)","Score Vent","Cat Vent","Ordre Cat Vent","Score M√©t√©o","Conditions Globales","Ordre Conditions Globales"})
in
    Final
```
<hr class="page-break">

### <a id="ann8">Annexe 8</a> : Exemple de mesure DAX de calcul des sensibilit√©s m√©t√©o

#### Mesures interm√©diaires pour le calcul de la sensibilit√© √† la pluie
```dax
MEASURE 'MesuresCat'[Cat Pluie] = VAR NP = [Niveau Pluie moyen]
RETURN
SWITCH(
    TRUE(),
    ISBLANK(NP), "Donn√©e manquante",
    NP = 0, "temps sec",
    NP <= 1, "bruine",                                  -- 0,5 mm en 30 min OU 1 mm tr√®s bri√®vement
    NP <= 3, "pluie faible",                            -- 2 mm en 1h OU 3 mm bri√®vement
    NP <= 7, "pluie mod√©r√©e : √©quipement n√©cessaire",   -- 5 mm pendant 1h = conditions humides s√©rieuses
    NP <= 12, "pluie forte : conditions difficiles",     -- 10 mm pendant 2h = vraiment d√©tremp√©
    "pluie dangereuse : cyclisme d√©conseill√©"           -- 15 mm pendant 3h = conditions extr√™mes
)

MEASURE 'MesuresNum'[Effet Pluie de R√©f√©rence] = VAR FluxMoyenSec = 
    CALCULATE(
        [Flux moyen],
        'meteo'[Cat Pluie] = "temps sec",
        ALL('comptage-velo-donnees-compteurs-allege'), -- enel√®ve les filtres sur la table de faits (p√©riode, compteur...)
        ALL('Calendrier')
    )
VAR FluxMoyenPluie = 
    CALCULATE(
        [Flux moyen],
        'meteo'[Cat Pluie] <> "temps sec",
        ALL('comptage-velo-donnees-compteurs-allege'), -- enel√®ve les filtres sur la table de faits (p√©riode, compteur...)
        ALL('Calendrier')
    )
RETURN
    DIVIDE(FluxMoyenPluie - FluxMoyenSec, FluxMoyenSec, 0)

MEASURE 'MesuresNum'[Effet Pluie] = VAR FluxMoyenSec = 
    CALCULATE(
        [Flux moyen],
        'meteo'[Cat Pluie] = "temps sec",
        KEEPFILTERS( meteo[Cat Pluie] = "temps sec" ),
        'comptage-velo-donnees-compteurs-allege'[comptage_horaire] >= 0 
    )
VAR FluxMoyenPluie = 
    CALCULATE(
        [Flux moyen],
        KEEPFILTERS( meteo[Cat Pluie] <> "temps sec" ),
        'comptage-velo-donnees-compteurs-allege'[comptage_horaire] >= 0 
    )
RETURN
    IF(
        ISBLANK(FluxMoyenSec),
        BLANK(),
        DIVIDE( FluxMoyenPluie - FluxMoyenSec, FluxMoyenSec, 0)
    )

MEASURE 'MesuresNum'[Nb Jours Secs] = VAR DatesAvecComptage =
    FILTER(
        VALUES( Calendrier[Date] ),   -- on it√®re sur les dates r√©elles (=contexte calendrier)
        CALCULATE(
            COUNTROWS( 'comptage-velo-donnees-compteurs-allege' ),  -- on v√©rifie qu'il existe au moins une ligne de comptage pour cette date,
            REMOVEFILTERS( 'compteurs_velo' )                       -- en ignorant les filtres sur la table des compteurs (site/compteur)
        ) > 0
    )
RETURN
CALCULATE(
    DISTINCTCOUNT(Calendrier[Date]),
    KEEPFILTERS(DatesAvecComptage),       -- on limite aux dates o√π il y a du comptage
    meteo[Cat Pluie] = "temps sec",       -- on filtre les jours secs
    REMOVEFILTERS(meteo)                  -- on emp√™che le contexte des lignes d‚Äô√©craser le filtre m√©t√©o
)

MEASURE 'MesuresNum'[Nb Jours Pluvieux] = VAR DatesAvecComptage =
    FILTER(
        VALUES( Calendrier[Date] ),  -- on it√®re sur les dates r√©elles (=contexte calendrier)
        CALCULATE(
            COUNTROWS( 'comptage-velo-donnees-compteurs-allege' ),  -- on v√©rifie qu'il existe au moins une ligne de comptage pour cette date,
            REMOVEFILTERS( 'compteurs_velo' )                       -- en ignorant les filtres sur la table des compteurs (site/compteur)
        ) > 0
    )
RETURN
CALCULATE(
    DISTINCTCOUNT(Calendrier[Date]),
    KEEPFILTERS(DatesAvecComptage),
    meteo[Cat Pluie] <> "temps sec",
    REMOVEFILTERS(meteo)  --emp√™che le contexte des lignes d‚Äô√©craser le filtre m√©t√©o
)
```
#### Mesure de la sensibilit√© √† la pluie
```dax
MEASURE 'MesuresNum'[Sensibilit√© √† la pluie (points de %)] = VAR BaisseContextuelle = [Effet Pluie]
VAR BaisseReference = [Effet Pluie de R√©f√©rence]
RETURN
    (BaisseContextuelle - BaisseReference) * 100
    MEASURE 'MesuresNum'[Nb Jours Secs] = VAR DatesAvecComptage =
    FILTER(
        VALUES( Calendrier[Date] ),   -- on it√®re sur les dates r√©elles (=contexte calendrier)
        CALCULATE(
            COUNTROWS( 'comptage-velo-donnees-compteurs-allege' ),  -- on v√©rifie qu'il existe au moins une ligne de comptage pour cette date,
            REMOVEFILTERS( 'compteurs_velo' )                       -- en ignorant les filtres sur la table des compteurs (site/compteur)
        ) > 0
    )
RETURN
CALCULATE(
    DISTINCTCOUNT(Calendrier[Date]),
    KEEPFILTERS(DatesAvecComptage),       -- on limite aux dates o√π il y a du comptage
    meteo[Cat Pluie] = "temps sec",       -- on filtre les jours secs
    REMOVEFILTERS(meteo)                  -- on emp√™che le contexte des lignes d‚Äô√©craser le filtre m√©t√©o
)
```
#### Mesures pour le choix dynamique de l'effet

```dax
MEASURE 'MesuresCat'[Axe d'analyse] = VALUES('Mesure s√©lectionn√©e'[Mesure s√©lectionn√©e Fields])

MEASURE 'MesuresNum'[Effet observ√©] = SWITCH(
    TRUE(),
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la pluie (points de %)]",[Effet Pluie],
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© au vent (points de %)]",[Effet Vent],
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la temp√©rature (points de %)]",[Effet Temp√©rature],
    [Effet M√©t√©o]
)

MEASURE 'MesuresNum'[Effet de r√©f√©rence] = SWITCH(
    TRUE(),
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la pluie (points de %)]",[Effet Pluie de R√©f√©rence],
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© au vent (points de %)]",[Effet Vent de R√©f√©rence],
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la temp√©rature (points de %)]",[Effet Temp√©rature de R√©f√©rence],
    [Effet M√©t√©o de R√©f√©rence]
)

MEASURE 'MesuresNum'[NbJours] = SWITCH(
    TRUE(),
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la pluie (points de %)]",MIN([Nb Jours Secs], [Nb Jours Pluvieux]),
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© au vent (points de %)]",MIN([Nb Jours Calmes], [Nb Jours Venteux]),
    [Axe d'analyse]="'MesuresNum'[Sensibilit√© √† la temp√©rature (points de %)]",MIN([Nb Jours Agr√©ables], [Nb Jours Moins Agr√©ables]),
    MIN([Nb Jours Excellents], [Nb Jours Non Excellents])
)
```
<hr class="page-break">

### <a id="ann9">Annexe 9</a> : Mesure DAX de calcul des jours d√©passant un seuil journalier

```dax
MEASURE 'Seuil Flux Journalier'[Seuil Flux Journalier Value] = SELECTEDVALUE('Seuil Flux Journalier'[Seuil Flux Journalier], 3000)
```
```dax
MEASURE 'MesuresNum'[Nb Jours Moyen au-dessus du Seuil] = VAR SeuilUtilisateur = SELECTEDVALUE('Seuil Flux Journalier'[Seuil Flux Journalier], 3000)
VAR TableSitesJours = 
    SUMMARIZE(
        'comptage-velo-donnees-compteurs-allege',
        'comptage-velo-donnees-compteurs-allege'[id_site],  
        'Calendrier'[Date],
        "FluxJour", [Flux total]
    )
VAR TableParSite = 
    ADDCOLUMNS(
        VALUES('comptage-velo-donnees-compteurs-allege'[id_site]),
        "@NbJoursAuDessus",
            VAR SiteActuel = 'comptage-velo-donnees-compteurs-allege'[id_site]
            RETURN
                COUNTROWS(
                    FILTER(
                        FILTER(
                            TableSitesJours,
                            'comptage-velo-donnees-compteurs-allege'[id_site] = SiteActuel
                        ),
                        [FluxJour] > SeuilUtilisateur
                    )
                )
    )
VAR NbJoursMoyen = AVERAGEX(TableParSite, [@NbJoursAuDessus])
RETURN
    NbJoursMoyen
```
```dax
MEASURE 'MesuresNum'[% Jours au-dessus du Seuil] = VAR DatesAvecComptage =
    FILTER(
        VALUES( Calendrier[Date] ),   -- on it√®re sur les dates r√©elles (=contexte calendrier)
        CALCULATE(
            COUNTROWS( 'comptage-velo-donnees-compteurs-allege' ),  -- on v√©rifie qu'il existe au moins une ligne de comptage pour cette date,
            REMOVEFILTERS( 'compteurs_velo' )                       -- en ignorant les filtres sur la table des compteurs (site/compteur)
        ) > 0
    )
VAR NbJoursPeriode = 
CALCULATE(
    DISTINCTCOUNT(Calendrier[Date]),
    KEEPFILTERS(DatesAvecComptage))       -- on limite aux dates o√π il y a du comptage
VAR NbJoursMoyenAuDessus = [Nb Jours Moyen au-dessus du Seuil]
RETURN
    DIVIDE(NbJoursMoyenAuDessus, NbJoursPeriode, 0)
```
```dax
MEASURE 'MesuresNum'[Card Analyse Seuil] = VAR Seuil = SELECTEDVALUE('Seuil Flux Journalier'[Seuil Flux Journalier], 3000)
VAR NbJoursMoyen = [Nb Jours Moyen au-dessus du Seuil]
VAR DatesAvecComptage =
    FILTER(
        VALUES( Calendrier[Date] ),   -- on it√®re sur les dates r√©elles (=contexte calendrier)
        CALCULATE(
            COUNTROWS( 'comptage-velo-donnees-compteurs-allege' ),  -- on v√©rifie qu'il existe au moins une ligne de comptage pour cette date,
            REMOVEFILTERS( 'compteurs_velo' )                       -- en ignorant les filtres sur la table des compteurs (site/compteur)
        ) > 0
    )
VAR NbJoursPeriode = 
CALCULATE(
    DISTINCTCOUNT(Calendrier[Date]),
    KEEPFILTERS(DatesAvecComptage))       -- on limite aux dates o√π il y a du comptage
VAR Pct = [% Jours au-dessus du Seuil]
VAR NbSites = DISTINCTCOUNT('comptage-velo-donnees-compteurs-allege'[id_site])
RETURN
    FORMAT(NbJoursMoyen, "0") & " jours au dessus / " & NbJoursPeriode & UNICHAR(10) &
    "Soit: " & FORMAT(Pct, "0%") & " des jours" & UNICHAR(10) &
    "(moy sur " & NbSites & " sites)"
```
<hr class="page-break">

### <a id="ann10">Annexe 10</a> : Script "nuage de mot" dans Power BI

````python
# The following code to create a dataframe and remove duplicated rows is always executed and acts as a preamble for your script: 

# dataset = pandas.DataFrame(commentaire, categorie, statut_proximite, Site de comptage)
# dataset = dataset.drop_duplicates()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nltk 
from nltk.corpus import stopwords

# pour √©viter d'importer des donn√©es externes dans Power BI, on importe la liste stop_word directement dans le script
stop_words=['ces', 'qu', 'ayons', 's', 'vraiment', 'seras', 'ait', 'f√ªmes', 'e√ªmes', 'auront', 'lui', 'l', 'on', 'fus', 'le', 'serai', '√©tant', 'son', 'et', 'sois', '√©taient', 'eue', 'cette', 'aurait', 'quand', 'qui', 'fusses', 'fut', 'ne', 'auraient', 'f√ªt', 'aie', 'mes', 'eusses', 'e√ªtes', 'tes', 'aies', 'avait', 'fussiez', 'vers', '√©tait', 'eu', 'avoir', 'avec', 'que', 't', 'aurions', 'seront', 'soient', 'pour', 'n', 'avaient', 'm√™me', '√©tants', 'pas', 'c', 'il', 'sur', 'sera', 'au', '√©tantes', 'serait', 'fusse', 'serais', 'ayante', '√©t√©es', 'furent', 'rue', 'cycliste', 'soyez', 'f√ªtes', 'd', 'auras', 'a', 'sont', '√©tais', 'e√ªt', 'du', 'me', '√™tre', 'avez', 'mais', 'aura', 'leur', 'moi', '√©t√©', 'se', 'ayant', 'une', 'vous', 'ayants', 'tu', '√©t√©s', 'suis', 'bd', 'la', 'es', 'aient', 'des', 'ta', 'aux', 'auriez', 'aurais', 'boulevard', 'j', 'v√©lo', 'ai', 'fussions', 'en', 'nos', 'ses', 'seraient', 'ils', 'eux', 'm', 'ont', 'nous', 'sommes', 'ce', 'je', 'serez', 'te', 'fussent', '√©tions', 'mon', '√†', 'avions', 'toi', 'eussent', 'seriez', 'ayantes', 'serons', "c'est", 'cyclable', 'votre', 'eues', 'aurai', 'eussiez', 'ou', 'notre', 'est', 'ayez', 'avenue', 'aurez', 'par', '√™tes', 'y', 'eus', 'de', 'sa', '√©tiez', '√©tante', 'avais', 'eut', 'aviez', 'route', 'elle', '√©t√©e', 'un', 'ton', 'les', 'vos', 'eurent', 'eusse', 'eussions', 'as', 'dans', 'aurons', 'avons', 'soyons', 'serions', 'soit', 'ma','piste']

corpus=dataset.loc[dataset.statut_proximite == "retenu","commentaire"].astype(str).tolist()

from sklearn.feature_extraction.text import TfidfVectorizer # pour application d'un algorithme TF_IDF

def creer_tfidf_dict(corpus):
    """
    Calcule les poids TF-IDF pour un corpus (liste de textes) et renvoie un dictionnaire {mot: score}.
    Pr√™t √† √™tre utilis√© avec WordCloud.generate_from_frequencies().

    corpus : list[str]  Liste de commentaires (d√©j√† nettoy√©s / lemmatis√©s / sans accent).
    """
    corpus_clean = [
        " ".join([mot for mot in texte.split() if mot.lower() not in stop_words])
        for texte in corpus
        if isinstance(texte, str) and texte.strip()
    ]
    if not corpus_clean:
        return {}  # s√©curit√© : √©vite les erreurs sur corpus vide
    
    # Adapter min_df et max_df dans les cas de petits corpus
    n_docs = len(corpus_clean)
    min_df_value = 2 if n_docs >= 2 else 1  # si moins de 2 documents, mettre min_df=1
    max_df_value = 0.9 if n_docs > 1 else 1.0

    vectorizer = TfidfVectorizer(
        max_df=max_df_value,             # ignore les mots trop fr√©quents
        min_df=min_df_value,    # ignore les mots trop rares... sauf si petit corpus
        norm='l2',              # normalisation standard
    )   
    
    tfidf_matrix = vectorizer.fit_transform(corpus_clean)
    tfidf_scores = np.asarray(tfidf_matrix.mean(axis=0)).ravel()  # on calcule le score moyen de chaque mot
    tfidf_dict = dict(zip(vectorizer.get_feature_names_out(), tfidf_scores))  # on r√©cup√®re ce score dans un dictionnaire qui va nous servir pour le nuage
    return tfidf_dict

# Compter les occurrences de chaque cat√©gorie
nb_rouge = dataset.loc[dataset.categorie == "rouge"].shape[0]
nb_vert = dataset.loc[dataset.categorie == "vert"].shape[0]

# Choisir la colormap selon la condition
colormap_choice = "inferno" if nb_rouge > nb_vert else "viridis"

from wordcloud import WordCloud  # pour les nuages de mots
tfidf_dict = creer_tfidf_dict(corpus)

plt.figure(figsize=(5,5))

if tfidf_dict:  # si le corpus contient des mots valides
    nuage = WordCloud(
        background_color="white",
        max_words=100,
        stopwords=stop_words,
        max_font_size=80,
        random_state=42,
        colormap=colormap_choice  # mettre inferno viridis sur du positif et inferno sur du n√©gatif, les 2 sont accessibles
    ).generate_from_frequencies(tfidf_dict)
    
    plt.imshow(nuage, interpolation='bilinear')
else:  # corpus vide ‚Üí affichage d'un message
    plt.text(
        0.5, 0.5,
        "Corpus de commentaire insuffisant\npour g√©n√©rer un nuage",
        fontsize=12,
        ha='center',
        va='center',
        wrap=True
    )    

# R√©cup√©rer le site unique correspondant au filtre
sites = dataset.loc[dataset.statut_proximite == "retenu", "Site de comptage"].unique()

# Si plusieurs sites sont retenus, on peut afficher "Plusieurs sites" ou concat√©ner
if len(sites) == 0:
    titre_site = "Aucun site"
elif len(sites) == 1:
    titre_site = sites[0]
else:
    titre_site = "Plusieurs sites"

plt.figure(figsize= (5,5)) 
plt.imshow(nuage, interpolation='bilinear')
plt.tight_layout(pad=0)  # supprime toute marge autour du graphique
plt.margins(0,0)         # pas d‚Äôespace autour du contenu
plt.subplots_adjust(left=0, right=1, top=0.95, bottom=0)
plt.title(titre_site, fontsize=14, fontweight='bold')
plt.axis("off")
plt.show()

````
